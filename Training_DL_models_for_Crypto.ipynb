{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T18:24:19.721498Z",
     "iopub.status.busy": "2025-09-07T18:24:19.721196Z",
     "iopub.status.idle": "2025-09-07T18:27:42.296023Z",
     "shell.execute_reply": "2025-09-07T18:27:42.294734Z",
     "shell.execute_reply.started": "2025-09-07T18:24:19.721476Z"
    },
    "id": "sKqFV1x2iF30",
    "outputId": "2163a224-e048-408d-8c62-1df683cf8279"
   },
   "outputs": [],
   "source": [
    "!run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU is available!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Use the GPU\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#####\n",
    "#####  VERSION 8\n",
    "#####\n",
    "#####\n",
    "\"\"\"\n",
    "Cryptocurrency Short-term Price Prediction System\n",
    "================================================\n",
    "\n",
    "A modular system for training and evaluating multiple deep learning and ensemble\n",
    "models for cryptocurrency price prediction (5-20 minute horizons).\n",
    "\n",
    "Author: AI Assistant\n",
    "License: MIT\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Data handling and preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Deep learning frameworks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# XGBoost for ensemble\n",
    "import xgboost as xgb\n",
    "\n",
    "# Data source\n",
    "#import ccxt\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Set the environment variable for PyTorch CUDA memory allocation\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available, using CPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    device = torch.device(\"cuda\")  # Use the GPU\n",
    "else:\n",
    "    print(\"GPU is not available, using CPU.\")\n",
    "    device = torch.device(\"cpu\")  # Use the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEXTENDING THE SYSTEM:\\n\\n1. Adding New Models:\\n   - Create a new model class inheriting from nn.Module (for PyTorch) or similar\\n   - Add training logic in ModelTrainer.train_all_models()\\n   - Add evaluation logic in ModelTrainer.evaluate_model()\\n   - Enable in Config.models_to_train\\n\\n2. Adding New Features:\\n   - Override CryptoPredictionSystem.add_custom_features()\\n   - Use load_external_features() and merge_external_features() for external data\\n   - Add feature engineering logic in DataLoader.engineer_features()\\n\\n3. Adding New Prediction Horizons:\\n   - Modify Config.prediction_horizons list\\n   - The system automatically handles multiple horizons\\n\\n4. Customizing Data Sources:\\n   - Modify DataLoader.fetch_crypto_data() for different exchanges/symbols\\n   - Override DataLoader.load_data() for different data formats\\n\\n5. Adding New Evaluation Metrics:\\n   - Extend ModelTrainer.evaluate_model()\\n   - Update ResultsAnalyzer for new visualizations\\n\\n6. Configuration Management:\\n   - Create new Config subclasses for different use cases\\n   - Save/load configurations using pickle or JSON\\n\\nExample Usage for Different Scenarios:\\n\\n# Quick test\\nsystem = CryptoPredictionSystem()\\nsystem.config = QuickTestConfig()\\nresults, output_dir = system.run_experiment(\"quick_test\")\\n\\n# With custom CSV data\\nsystem = CryptoPredictionSystem(\"my_data.csv\")\\nresults, output_dir = system.run_experiment(\"custom_data_experiment\")\\n\\n# Production setup\\nsystem = CryptoPredictionSystem()\\nsystem.config = ProductionConfig()\\nresults, output_dir = system.run_experiment(\"production_run\")\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration class for the prediction system.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Data parameters\n",
    "        self.csv_file = None\n",
    "        self.timestamp_col = 'Timestamp'\n",
    "        self.required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        self.target_col = 'Close'\n",
    "        self.prediction_horizons = [5, 10, 15, 20]  # minutes\n",
    "        self.sequence_length = 60  # lookback window\n",
    "        \n",
    "        # Model parameters\n",
    "        self.lstm_hidden_size = 64\n",
    "        self.lstm_num_layers = 2\n",
    "        self.cnn_filters = 32\n",
    "        self.transformer_d_model = 64\n",
    "        self.transformer_nhead = 8\n",
    "        self.transformer_num_layers = 2\n",
    "        \n",
    "        # Training parameters\n",
    "        self.batch_size = 32\n",
    "        self.epochs = 50\n",
    "        self.learning_rate = 0.001\n",
    "        self.train_ratio = 0.7\n",
    "        self.val_ratio = 0.15\n",
    "        self.test_ratio = 0.15\n",
    "        \n",
    "        # Device\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Models to train\n",
    "        self.models_to_train = {\n",
    "            'LSTM': True,\n",
    "            'CNN_LSTM': True,\n",
    "            'Transformer': True,\n",
    "            'LSTM_XGBoost': True,\n",
    "            'RL_Agent': False  # Optional, set to True to enable\n",
    "        }\n",
    "        \n",
    "        # Output directory\n",
    "        self.output_dir = 'crypto_prediction_results'\n",
    "\n",
    "\n",
    "class CryptoDataLoader:\n",
    "    \"\"\"Handles data loading, preprocessing, and feature engineering.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.scaler = StandardScaler()\n",
    "        self.price_scaler = MinMaxScaler()\n",
    "        self.data = None\n",
    "        self.features = None\n",
    "        self.targets = {}\n",
    "        \n",
    "    def fetch_crypto_data(self, symbol='BTC/USD', timeframe='1m', limit=500):\n",
    "        \"\"\"Fetch real cryptocurrency data using CCXT.\"\"\"\n",
    "        print(f\"Fetching {symbol} data from Coinbase...\")\n",
    "        \n",
    "        try:\n",
    "            exchange = ccxt.coinbase()\n",
    "            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)\n",
    "            \n",
    "            df = pd.DataFrame(ohlcv, columns=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "            df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='ms')\n",
    "            \n",
    "            print(f\"Successfully fetched {len(df)} candles\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_data(self, csv_file: Optional[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"Load data from CSV file or fetch from API.\"\"\"\n",
    "        if csv_file and os.path.exists(csv_file):\n",
    "            print(f\"Loading data from {csv_file}\")\n",
    "            self.data = pd.read_csv(csv_file)\n",
    "            self.data[self.config.timestamp_col] = pd.to_datetime(self.data[self.config.timestamp_col])\n",
    "        else:\n",
    "            print(\"No CSV file provided or file not found. Fetching live data...\")\n",
    "            self.data = self.fetch_crypto_data()\n",
    "            \n",
    "            if self.data is None:\n",
    "                raise ValueError(\"Could not load or fetch data\")\n",
    "        \n",
    "        # Ensure required columns exist\n",
    "        missing_cols = [col for col in self.config.required_cols if col not in self.data.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Sort by timestamp\n",
    "        self.data = self.data.sort_values(self.config.timestamp_col).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Loaded data shape: {self.data.shape}\")\n",
    "        print(f\"Date range: {self.data[self.config.timestamp_col].min()} to {self.data[self.config.timestamp_col].max()}\")\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def engineer_features(self) -> pd.DataFrame:\n",
    "        \"\"\"Engineer technical indicators and other features.\"\"\"\n",
    "        print(\"Engineering features...\")\n",
    "        \n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # Basic price features\n",
    "        df['Price_Change'] = df['Close'].pct_change()\n",
    "        df['Price_Range'] = df['High'] - df['Low']\n",
    "        df['Price_Position'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'])\n",
    "        \n",
    "        # Technical indicators\n",
    "        # Simple Moving Averages\n",
    "        for window in [5, 10, 20]:\n",
    "            df[f'SMA_{window}'] = df['Close'].rolling(window=window).mean()\n",
    "            df[f'Price_to_SMA_{window}'] = df['Close'] / df[f'SMA_{window}']\n",
    "        \n",
    "        # Exponential Moving Average\n",
    "        df['EMA_12'] = df['Close'].ewm(span=12).mean()\n",
    "        df['EMA_26'] = df['Close'].ewm(span=26).mean()\n",
    "        df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        df['BB_Middle'] = df['Close'].rolling(window=20).mean()\n",
    "        df['BB_Std'] = df['Close'].rolling(window=20).std()\n",
    "        df['BB_Upper'] = df['BB_Middle'] + (df['BB_Std'] * 2)\n",
    "        df['BB_Lower'] = df['BB_Middle'] - (df['BB_Std'] * 2)\n",
    "        df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])\n",
    "        \n",
    "        # RSI\n",
    "        delta = df['Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / loss\n",
    "        df['RSI'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # Volume features\n",
    "        df['Volume_SMA'] = df['Volume'].rolling(window=20).mean()\n",
    "        df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA']\n",
    "        \n",
    "        # Volatility\n",
    "        df['Volatility'] = df['Close'].rolling(window=20).std()\n",
    "        \n",
    "        # Time-based features\n",
    "        df['Hour'] = df[self.config.timestamp_col].dt.hour\n",
    "        df['DayOfWeek'] = df[self.config.timestamp_col].dt.dayofweek\n",
    "        df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(int)\n",
    "        \n",
    "        # Drop rows with NaN values\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Feature engineering complete. Shape: {df.shape}\")\n",
    "        \n",
    "        # Select features (exclude timestamp and target)\n",
    "        feature_cols = [col for col in df.columns \n",
    "                       if col not in [self.config.timestamp_col, self.config.target_col]]\n",
    "        \n",
    "        self.features = df[feature_cols].copy()\n",
    "        self.data = df\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_targets(self) -> Dict[int, np.ndarray]:\n",
    "        \"\"\"Create target variables for different prediction horizons.\"\"\"\n",
    "        print(\"Creating target variables...\")\n",
    "        \n",
    "        targets = {}\n",
    "        for horizon in self.config.prediction_horizons:\n",
    "            # Price change after 'horizon' minutes\n",
    "            future_price = self.data[self.config.target_col].shift(-horizon)\n",
    "            targets[horizon] = future_price.values\n",
    "        \n",
    "        # Remove last 'max_horizon' rows as they don't have targets\n",
    "        max_horizon = max(self.config.prediction_horizons)\n",
    "        for horizon in targets:\n",
    "            targets[horizon] = targets[horizon][:-max_horizon]\n",
    "        \n",
    "        # Update features to match target length\n",
    "        self.features = self.features.iloc[:-max_horizon].copy()\n",
    "        \n",
    "        self.targets = targets\n",
    "        print(f\"Target variables created for horizons: {list(targets.keys())}\")\n",
    "        \n",
    "        return targets\n",
    "    \n",
    "    def prepare_sequences(self, features: np.ndarray, targets: np.ndarray, \n",
    "                         sequence_length: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Prepare sequential data for time series models.\"\"\"\n",
    "        X, y = [], []\n",
    "        \n",
    "        for i in range(sequence_length, len(features)):\n",
    "            X.append(features[i-sequence_length:i])\n",
    "            y.append(targets[i])\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def split_data(self, horizon: int) -> Dict[str, Any]:\n",
    "        \"\"\"Split data into train, validation, and test sets.\"\"\"\n",
    "        print(f\"Splitting data for {horizon}-minute horizon...\")\n",
    "        \n",
    "        # Scale features\n",
    "        scaled_features = self.scaler.fit_transform(self.features)\n",
    "        targets = self.targets[horizon]\n",
    "        \n",
    "        # Remove NaN targets\n",
    "        valid_indices = ~np.isnan(targets)\n",
    "        scaled_features = scaled_features[valid_indices]\n",
    "        targets = targets[valid_indices]\n",
    "        \n",
    "        # Calculate split indices\n",
    "        n_samples = len(scaled_features)\n",
    "        train_end = int(n_samples * self.config.train_ratio)\n",
    "        val_end = int(n_samples * (self.config.train_ratio + self.config.val_ratio))\n",
    "        \n",
    "        # Create sequences\n",
    "        X_seq, y_seq = self.prepare_sequences(scaled_features, targets, self.config.sequence_length)\n",
    "        \n",
    "        # Split sequences\n",
    "        train_end_seq = max(0, train_end - self.config.sequence_length)\n",
    "        val_end_seq = max(train_end_seq, val_end - self.config.sequence_length)\n",
    "        \n",
    "        X_train = X_seq[:train_end_seq]\n",
    "        y_train = y_seq[:train_end_seq]\n",
    "        X_val = X_seq[train_end_seq:val_end_seq]\n",
    "        y_val = y_seq[train_end_seq:val_end_seq]\n",
    "        X_test = X_seq[val_end_seq:]\n",
    "        y_test = y_seq[val_end_seq:]\n",
    "        \n",
    "        # Also prepare non-sequential data for XGBoost\n",
    "        X_train_flat = scaled_features[self.config.sequence_length:train_end]\n",
    "        X_val_flat = scaled_features[train_end:val_end]\n",
    "        X_test_flat = scaled_features[val_end:]\n",
    "        \n",
    "        y_train_flat = targets[self.config.sequence_length:train_end]\n",
    "        y_val_flat = targets[train_end:val_end]\n",
    "        y_test_flat = targets[val_end:]\n",
    "        \n",
    "        return {\n",
    "            'X_train': X_train, 'y_train': y_train,\n",
    "            'X_val': X_val, 'y_val': y_val,\n",
    "            'X_test': X_test, 'y_test': y_test,\n",
    "            'X_train_flat': X_train_flat, 'y_train_flat': y_train_flat,\n",
    "            'X_val_flat': X_val_flat, 'y_val_flat': y_val_flat,\n",
    "            'X_test_flat': X_test_flat, 'y_test_flat': y_test_flat\n",
    "        }\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"Standard LSTM model for time series prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int, output_size: int = 1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])  # Take last output\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNLSTMModel(nn.Module):\n",
    "    \"\"\"CNN-LSTM hybrid model.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size: int, cnn_filters: int, hidden_size: int, \n",
    "                 num_layers: int, output_size: int = 1):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        \n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv1d(input_size, cnn_filters, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(cnn_filters, cnn_filters*2, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(cnn_filters*2, hidden_size, num_layers, \n",
    "                           batch_first=True, dropout=0.2)\n",
    "        \n",
    "        # Output layers\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, features = x.size()\n",
    "        \n",
    "        # CNN processing\n",
    "        x = x.transpose(1, 2)  # (batch, features, seq_len)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Back to LSTM format\n",
    "        x = x.transpose(1, 2)  # (batch, seq_len, features)\n",
    "        \n",
    "        # LSTM processing\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Output\n",
    "        out = self.dropout(lstm_out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Transformer-based time series model.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size: int, d_model: int, nhead: int, \n",
    "                 num_layers: int, output_size: int = 1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.input_projection = nn.Linear(input_size, d_model)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1000, d_model))\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, batch_first=True, dropout=0.1\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(d_model, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Project input to d_model dimensions\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = x + self.positional_encoding[:seq_len].unsqueeze(0)\n",
    "        \n",
    "        # Transformer processing\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # Take mean of sequence for prediction\n",
    "        x = torch.mean(x, dim=1)\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class RLAgent:\n",
    "    \"\"\"Simple RL agent for trading signals (placeholder implementation).\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size: int, action_size: int = 3):  # Buy, Hold, Sell\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = []\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "        self.learning_rate = 0.001\n",
    "        \n",
    "        # Simple neural network for Q-learning\n",
    "        self.q_network = nn.Sequential(\n",
    "            nn.Linear(state_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, action_size)\n",
    "        )\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=self.learning_rate)\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        \"\"\"Get action from current policy.\"\"\"\n",
    "        if np.random.random() <= self.epsilon:\n",
    "            return np.random.randint(self.action_size)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            q_values = self.q_network(torch.FloatTensor(state))\n",
    "            return q_values.argmax().item()\n",
    "    \n",
    "    def train(self, experiences):\n",
    "        \"\"\"Train the RL agent (simplified implementation).\"\"\"\n",
    "        # This is a placeholder for a more comprehensive RL implementation\n",
    "        pass\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Handles training and evaluation of all models.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def train_pytorch_model(self, model, train_loader, val_loader, horizon: int, model_name: str):\n",
    "        \"\"\"Train a PyTorch model.\"\"\"\n",
    "        print(f\"Training {model_name} for {horizon}-minute horizon...\")\n",
    "        \n",
    "        model = model.to(self.config.device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=self.config.learning_rate)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(self.config.epochs):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X = batch_X.to(self.config.device)\n",
    "                batch_y = batch_y.to(self.config.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs.squeeze(), batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for batch_X, batch_y in val_loader:\n",
    "                    batch_X = batch_X.to(self.config.device)\n",
    "                    batch_y = batch_y.to(self.config.device)\n",
    "                    outputs = model(batch_X)\n",
    "                    val_loss += criterion(outputs.squeeze(), batch_y).item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            \n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                torch.save(model.state_dict(), f'{model_name}_{horizon}min_best.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch}: Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}')\n",
    "            \n",
    "            if patience_counter >= 10:  # Early stopping\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "        \n",
    "        # Load best model\n",
    "        model.load_state_dict(torch.load(f'{model_name}_{horizon}min_best.pth'))\n",
    "        return model\n",
    "    \n",
    "    def train_xgboost_model(self, X_train, y_train, X_val, y_val, horizon: int):\n",
    "        \"\"\"Train XGBoost model.\"\"\"\n",
    "        print(f\"Training XGBoost for {horizon}-minute horizon...\")\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        \n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.1,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params, dtrain,\n",
    "            num_boost_round=100,\n",
    "            evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "            early_stopping_rounds=10,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def create_ensemble_features(self, X_data, lstm_model, cnn_lstm_model, transformer_model):\n",
    "        \"\"\"Create features for ensemble model using predictions from other models.\"\"\"\n",
    "        lstm_model.eval()\n",
    "        cnn_lstm_model.eval()\n",
    "        transformer_model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.FloatTensor(X_data).to(self.config.device)\n",
    "            \n",
    "            lstm_preds = lstm_model(X_tensor).cpu().numpy().flatten()\n",
    "            cnn_lstm_preds = cnn_lstm_model(X_tensor).cpu().numpy().flatten()\n",
    "            transformer_preds = transformer_model(X_tensor).cpu().numpy().flatten()\n",
    "        \n",
    "        # Combine original features with model predictions\n",
    "        X_flat = X_data.reshape(X_data.shape[0], -1)\n",
    "        ensemble_features = np.column_stack([\n",
    "            X_flat, lstm_preds, cnn_lstm_preds, transformer_preds\n",
    "        ])\n",
    "        \n",
    "        return ensemble_features\n",
    "    \n",
    "    def evaluate_model(self, model, X_test, y_test, model_name: str, horizon: int, is_pytorch: bool = True):\n",
    "        \"\"\"Evaluate model performance.\"\"\"\n",
    "        if is_pytorch:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                if isinstance(X_test, np.ndarray):\n",
    "                    X_test_tensor = torch.FloatTensor(X_test).to(self.config.device)\n",
    "                else:\n",
    "                    X_test_tensor = X_test.to(self.config.device)\n",
    "                predictions = model(X_test_tensor).cpu().numpy().flatten()\n",
    "        else:  # XGBoost\n",
    "            if isinstance(X_test, np.ndarray):\n",
    "                dtest = xgb.DMatrix(X_test)\n",
    "            else:\n",
    "                dtest = X_test\n",
    "            predictions = model.predict(dtest)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        return {\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "    \n",
    "    def train_all_models(self, data_loader: CryptoDataLoader):\n",
    "        \"\"\"Train all enabled models.\"\"\"\n",
    "        print(\"Starting model training...\")\n",
    "        \n",
    "        os.makedirs(self.config.output_dir, exist_ok=True)\n",
    "        \n",
    "        for horizon in self.config.prediction_horizons:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Training models for {horizon}-minute horizon\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # Get data splits for this horizon\n",
    "            data_splits = data_loader.split_data(horizon)\n",
    "            \n",
    "            # Prepare data loaders\n",
    "            X_train_tensor = torch.FloatTensor(data_splits['X_train'])\n",
    "            y_train_tensor = torch.FloatTensor(data_splits['y_train'])\n",
    "            train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)\n",
    "            \n",
    "            X_val_tensor = torch.FloatTensor(data_splits['X_val'])\n",
    "            y_val_tensor = torch.FloatTensor(data_splits['y_val'])\n",
    "            val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size, shuffle=False)\n",
    "            \n",
    "            input_size = data_splits['X_train'].shape[2]\n",
    "            horizon_results = {}\n",
    "            \n",
    "            # Train LSTM\n",
    "            if self.config.models_to_train['LSTM']:\n",
    "                lstm_model = LSTMModel(\n",
    "                    input_size=input_size,\n",
    "                    hidden_size=self.config.lstm_hidden_size,\n",
    "                    num_layers=self.config.lstm_num_layers\n",
    "                )\n",
    "                lstm_model = self.train_pytorch_model(lstm_model, train_loader, val_loader, horizon, 'LSTM')\n",
    "                \n",
    "                # Evaluate\n",
    "                lstm_results = self.evaluate_model(\n",
    "                    lstm_model, data_splits['X_test'], data_splits['y_test'], 'LSTM', horizon\n",
    "                )\n",
    "                horizon_results['LSTM'] = lstm_results\n",
    "                \n",
    "                # Store model\n",
    "                if horizon not in self.models:\n",
    "                    self.models[horizon] = {}\n",
    "                self.models[horizon]['LSTM'] = lstm_model\n",
    "            \n",
    "            # Train CNN-LSTM\n",
    "            if self.config.models_to_train['CNN_LSTM']:\n",
    "                cnn_lstm_model = CNNLSTMModel(\n",
    "                    input_size=input_size,\n",
    "                    cnn_filters=self.config.cnn_filters,\n",
    "                    hidden_size=self.config.lstm_hidden_size,\n",
    "                    num_layers=self.config.lstm_num_layers\n",
    "                )\n",
    "                cnn_lstm_model = self.train_pytorch_model(cnn_lstm_model, train_loader, val_loader, horizon, 'CNN_LSTM')\n",
    "                \n",
    "                # Evaluate\n",
    "                cnn_lstm_results = self.evaluate_model(\n",
    "                    cnn_lstm_model, data_splits['X_test'], data_splits['y_test'], 'CNN_LSTM', horizon\n",
    "                )\n",
    "                horizon_results['CNN_LSTM'] = cnn_lstm_results\n",
    "                \n",
    "                # Store model\n",
    "                self.models[horizon]['CNN_LSTM'] = cnn_lstm_model\n",
    "            \n",
    "            # Train Transformer\n",
    "            if self.config.models_to_train['Transformer']:\n",
    "                transformer_model = TransformerModel(\n",
    "                    input_size=input_size,\n",
    "                    d_model=self.config.transformer_d_model,\n",
    "                    nhead=self.config.transformer_nhead,\n",
    "                    num_layers=self.config.transformer_num_layers\n",
    "                )\n",
    "                transformer_model = self.train_pytorch_model(transformer_model, train_loader, val_loader, horizon, 'Transformer')\n",
    "                \n",
    "                # Evaluate\n",
    "                transformer_results = self.evaluate_model(\n",
    "                    transformer_model, data_splits['X_test'], data_splits['y_test'], 'Transformer', horizon\n",
    "                )\n",
    "                horizon_results['Transformer'] = transformer_results\n",
    "                \n",
    "                # Store model\n",
    "                self.models[horizon]['Transformer'] = transformer_model\n",
    "            \n",
    "            # Train LSTM + XGBoost Ensemble\n",
    "            if self.config.models_to_train['LSTM_XGBoost']:\n",
    "                if 'LSTM' in self.models[horizon] and 'CNN_LSTM' in self.models[horizon] and 'Transformer' in self.models[horizon]:\n",
    "                    # Create ensemble features\n",
    "                    ensemble_X_train = self.create_ensemble_features(\n",
    "                        data_splits['X_train'],\n",
    "                        self.models[horizon]['LSTM'],\n",
    "                        self.models[horizon]['CNN_LSTM'],\n",
    "                        self.models[horizon]['Transformer']\n",
    "                    )\n",
    "                    ensemble_X_val = self.create_ensemble_features(\n",
    "                        data_splits['X_val'],\n",
    "                        self.models[horizon]['LSTM'],\n",
    "                        self.models[horizon]['CNN_LSTM'],\n",
    "                        self.models[horizon]['Transformer']\n",
    "                    )\n",
    "                    ensemble_X_test = self.create_ensemble_features(\n",
    "                        data_splits['X_test'],\n",
    "                        self.models[horizon]['LSTM'],\n",
    "                        self.models[horizon]['CNN_LSTM'],\n",
    "                        self.models[horizon]['Transformer']\n",
    "                    )\n",
    "                    \n",
    "                    # Train XGBoost ensemble\n",
    "                    xgb_ensemble = self.train_xgboost_model(\n",
    "                        ensemble_X_train, data_splits['y_train'],\n",
    "                        ensemble_X_val, data_splits['y_val'],\n",
    "                        horizon\n",
    "                    )\n",
    "                    \n",
    "                    # Evaluate\n",
    "                    ensemble_results = self.evaluate_model(\n",
    "                        xgb_ensemble, xgb.DMatrix(ensemble_X_test), data_splits['y_test'],\n",
    "                        'LSTM_XGBoost', horizon, is_pytorch=False\n",
    "                    )\n",
    "                    horizon_results['LSTM_XGBoost'] = ensemble_results\n",
    "                    \n",
    "                    # Store model\n",
    "                    self.models[horizon]['LSTM_XGBoost'] = xgb_ensemble\n",
    "                    \n",
    "                else:\n",
    "                    print(\"Cannot train ensemble - not all base models available\")\n",
    "            \n",
    "            # Train RL Agent (placeholder)\n",
    "            if self.config.models_to_train['RL_Agent']:\n",
    "                print(\"RL Agent training is a placeholder - implement according to your needs\")\n",
    "                # rl_agent = RLAgent(state_size=input_size * self.config.sequence_length)\n",
    "                # # Implement RL training logic here\n",
    "                # horizon_results['RL_Agent'] = {'MAE': 0, 'RMSE': 0, 'R2': 0}\n",
    "            \n",
    "            # Store results for this horizon\n",
    "            self.results[horizon] = horizon_results\n",
    "            \n",
    "            # Print results summary\n",
    "            print(f\"\\nResults for {horizon}-minute horizon:\")\n",
    "            print(\"-\" * 40)\n",
    "            for model_name, results in horizon_results.items():\n",
    "                print(f\"{model_name:15} - MAE: {results['MAE']:.4f}, RMSE: {results['RMSE']:.4f}, R2: {results['R2']:.4f}\")\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "\n",
    "class ResultsAnalyzer:\n",
    "    \"\"\"Analyzes and visualizes model results.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        \n",
    "    def create_results_summary(self, results: Dict) -> pd.DataFrame:\n",
    "        \"\"\"Create a summary DataFrame of all results.\"\"\"\n",
    "        summary_data = []\n",
    "        \n",
    "        for horizon, horizon_results in results.items():\n",
    "            for model_name, metrics in horizon_results.items():\n",
    "                summary_data.append({\n",
    "                    'Horizon (min)': horizon,\n",
    "                    'Model': model_name,\n",
    "                    'MAE': metrics['MAE'],\n",
    "                    'RMSE': metrics['RMSE'],\n",
    "                    'R2': metrics['R2']\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(summary_data)\n",
    "    \n",
    "    def plot_results_comparison(self, results: Dict, save_path: str = None):\n",
    "        \"\"\"Create comparison plots for all models and horizons.\"\"\"\n",
    "        summary_df = self.create_results_summary(results)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle('Model Performance Comparison Across Prediction Horizons', fontsize=16)\n",
    "        \n",
    "        # MAE comparison\n",
    "        pivot_mae = summary_df.pivot(index='Horizon (min)', columns='Model', values='MAE')\n",
    "        pivot_mae.plot(kind='bar', ax=axes[0, 0])\n",
    "        axes[0, 0].set_title('Mean Absolute Error (MAE)')\n",
    "        axes[0, 0].set_ylabel('MAE')\n",
    "        axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # RMSE comparison\n",
    "        pivot_rmse = summary_df.pivot(index='Horizon (min)', columns='Model', values='RMSE')\n",
    "        pivot_rmse.plot(kind='bar', ax=axes[0, 1])\n",
    "        axes[0, 1].set_title('Root Mean Square Error (RMSE)')\n",
    "        axes[0, 1].set_ylabel('RMSE')\n",
    "        axes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # R2 comparison\n",
    "        pivot_r2 = summary_df.pivot(index='Horizon (min)', columns='Model', values='R2')\n",
    "        pivot_r2.plot(kind='bar', ax=axes[1, 0])\n",
    "        axes[1, 0].set_title('R-squared (R²)')\n",
    "        axes[1, 0].set_ylabel('R²')\n",
    "        axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # Best model per horizon (based on R2)\n",
    "        best_models = summary_df.loc[summary_df.groupby('Horizon (min)')['R2'].idxmax()]\n",
    "        axes[1, 1].bar(best_models['Horizon (min)'], best_models['R2'], \n",
    "                      color=['red', 'blue', 'green', 'orange'][:len(best_models)])\n",
    "        axes[1, 1].set_title('Best Model R² by Horizon')\n",
    "        axes[1, 1].set_xlabel('Horizon (minutes)')\n",
    "        axes[1, 1].set_ylabel('R²')\n",
    "        \n",
    "        # Add model names as labels\n",
    "        for i, (horizon, r2) in enumerate(zip(best_models['Horizon (min)'], best_models['R2'])):\n",
    "            axes[1, 1].text(horizon, r2 + 0.01, best_models.iloc[i]['Model'], \n",
    "                           ha='center', rotation=45, fontsize=8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return summary_df\n",
    "    \n",
    "    def plot_predictions_vs_actual(self, results: Dict, horizon: int, save_path: str = None):\n",
    "        \"\"\"Plot predictions vs actual values for a specific horizon.\"\"\"\n",
    "        if horizon not in results:\n",
    "            print(f\"No results available for {horizon}-minute horizon\")\n",
    "            return\n",
    "        \n",
    "        horizon_results = results[horizon]\n",
    "        n_models = len(horizon_results)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (model_name, model_results) in enumerate(horizon_results.items()):\n",
    "            if i >= 4:  # Only plot first 4 models\n",
    "                break\n",
    "                \n",
    "            predictions = model_results['predictions'][:100]  # Plot first 100 predictions\n",
    "            actual = range(len(predictions))\n",
    "            \n",
    "            axes[i].scatter(range(len(predictions)), predictions, alpha=0.6, label='Predictions')\n",
    "            axes[i].plot(range(len(predictions)), predictions, alpha=0.8)\n",
    "            axes[i].set_title(f'{model_name} - {horizon}min horizon')\n",
    "            axes[i].set_xlabel('Time Step')\n",
    "            axes[i].set_ylabel('Price')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for i in range(n_models, 4):\n",
    "            axes[i].set_visible(False)\n",
    "        \n",
    "        plt.suptitle(f'Predictions for {horizon}-minute Horizon (First 100 predictions)', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def save_results(self, results: Dict, models: Dict, save_dir: str):\n",
    "        \"\"\"Save all results and models to disk.\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Save results summary\n",
    "        summary_df = self.create_results_summary(results)\n",
    "        summary_df.to_csv(os.path.join(save_dir, 'results_summary.csv'), index=False)\n",
    "        \n",
    "        # Save detailed results\n",
    "        with open(os.path.join(save_dir, 'detailed_results.json'), 'w') as f:\n",
    "            # Convert numpy arrays to lists for JSON serialization\n",
    "            json_results = {}\n",
    "            for horizon, horizon_results in results.items():\n",
    "                json_results[str(horizon)] = {}\n",
    "                for model_name, metrics in horizon_results.items():\n",
    "                    json_results[str(horizon)][model_name] = {\n",
    "                        'MAE': float(metrics['MAE']),\n",
    "                        'RMSE': float(metrics['RMSE']),\n",
    "                        'R2': float(metrics['R2']),\n",
    "                        'predictions': metrics['predictions'].tolist() if 'predictions' in metrics else []\n",
    "                    }\n",
    "            json.dump(json_results, f, indent=2)\n",
    "        \n",
    "        # Save PyTorch models\n",
    "        for horizon, horizon_models in models.items():\n",
    "            for model_name, model in horizon_models.items():\n",
    "                if hasattr(model, 'state_dict'):  # PyTorch model\n",
    "                    torch.save(model.state_dict(), \n",
    "                             os.path.join(save_dir, f'{model_name}_{horizon}min.pth'))\n",
    "                elif hasattr(model, 'save_model'):  # XGBoost model\n",
    "                    model.save_model(os.path.join(save_dir, f'{model_name}_{horizon}min.json'))\n",
    "        \n",
    "        print(f\"Results and models saved to {save_dir}\")\n",
    "\n",
    "\n",
    "class CryptoPredictionSystem:\n",
    "    \"\"\"Main system class that orchestrates the entire prediction pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file: str = None):\n",
    "        self.config = Config()\n",
    "        if csv_file:\n",
    "            self.config.csv_file = csv_file\n",
    "        \n",
    "        self.data_loader = CryptoDataLoader(self.config)\n",
    "        self.trainer = ModelTrainer(self.config)\n",
    "        self.analyzer = ResultsAnalyzer(self.config)\n",
    "    \n",
    "    def add_custom_features(self, feature_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Add custom features to the dataset.\n",
    "        \n",
    "        Override this method to add domain-specific features like:\n",
    "        - Sentiment scores from news/social media\n",
    "        - Market microstructure features\n",
    "        - Cross-asset correlations\n",
    "        - Event-based indicators\n",
    "        \n",
    "        Args:\n",
    "            feature_df: DataFrame with current features\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with additional features\n",
    "        \"\"\"\n",
    "        # No custom features added by default\n",
    "        # Override this method to add your own features\n",
    "        return feature_df\n",
    "    \n",
    "    def run_experiment(self, experiment_name: str = \"crypto_prediction_experiment\"):\n",
    "        \"\"\"Run the complete prediction experiment.\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"CRYPTOCURRENCY PRICE PREDICTION SYSTEM\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Load and prepare data\n",
    "            print(\"\\n1. Loading and preparing data...\")\n",
    "            self.data_loader.load_data(self.config.csv_file)\n",
    "            self.data_loader.engineer_features()\n",
    "            \n",
    "            # Add custom features (can be overridden)\n",
    "            self.data_loader.features = self.add_custom_features(self.data_loader.features)\n",
    "            \n",
    "            self.data_loader.create_targets()\n",
    "            \n",
    "            print(f\"Final feature shape: {self.data_loader.features.shape}\")\n",
    "            print(f\"Available features: {list(self.data_loader.features.columns)}\")\n",
    "            \n",
    "            # Step 2: Train all models\n",
    "            print(\"\\n2. Training models...\")\n",
    "            results = self.trainer.train_all_models(self.data_loader)\n",
    "            \n",
    "            # Step 3: Analyze results\n",
    "            print(\"\\n3. Analyzing results...\")\n",
    "            \n",
    "            # Create output directory with timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_dir = f\"{self.config.output_dir}_{experiment_name}_{timestamp}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # Generate summary\n",
    "            summary_df = self.analyzer.create_results_summary(results)\n",
    "            print(\"\\nResults Summary:\")\n",
    "            print(\"=\" * 80)\n",
    "            print(summary_df.to_string(index=False))\n",
    "            \n",
    "            # Create visualizations\n",
    "            print(\"\\n4. Creating visualizations...\")\n",
    "            \n",
    "            # Overall comparison\n",
    "            self.analyzer.plot_results_comparison(\n",
    "                results, \n",
    "                save_path=os.path.join(output_dir, 'model_comparison.png')\n",
    "            )\n",
    "            \n",
    "            # Predictions vs actual for each horizon\n",
    "            for horizon in self.config.prediction_horizons:\n",
    "                self.analyzer.plot_predictions_vs_actual(\n",
    "                    results, horizon,\n",
    "                    save_path=os.path.join(output_dir, f'predictions_{horizon}min.png')\n",
    "                )\n",
    "            \n",
    "            # Step 5: Save results\n",
    "            print(\"\\n5. Saving results...\")\n",
    "            self.analyzer.save_results(results, self.trainer.models, output_dir)\n",
    "            \n",
    "            # Print best models\n",
    "            print(\"\\nBest Models by Horizon (based on R²):\")\n",
    "            print(\"-\" * 40)\n",
    "            best_models = summary_df.loc[summary_df.groupby('Horizon (min)')['R2'].idxmax()]\n",
    "            for _, row in best_models.iterrows():\n",
    "                print(f\"{row['Horizon (min)']}min: {row['Model']} (R²: {row['R2']:.4f})\")\n",
    "            \n",
    "            print(f\"\\nExperiment completed! Results saved to: {output_dir}\")\n",
    "            \n",
    "            return results, output_dir\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during experiment: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None, None\n",
    "    \n",
    "    def predict_future(self, horizon: int, model_name: str = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Make predictions for future time steps.\n",
    "        \n",
    "        Args:\n",
    "            horizon: Prediction horizon in minutes\n",
    "            model_name: Name of model to use (if None, uses best model)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with prediction results\n",
    "        \"\"\"\n",
    "        if horizon not in self.trainer.models:\n",
    "            raise ValueError(f\"No models trained for {horizon}-minute horizon\")\n",
    "        \n",
    "        available_models = list(self.trainer.models[horizon].keys())\n",
    "        \n",
    "        if model_name is None:\n",
    "            # Use the first available model (or implement logic to select best)\n",
    "            model_name = available_models[0]\n",
    "        elif model_name not in available_models:\n",
    "            raise ValueError(f\"Model {model_name} not available. Available: {available_models}\")\n",
    "        \n",
    "        model = self.trainer.models[horizon][model_name]\n",
    "        \n",
    "        # Get latest data for prediction\n",
    "        latest_data = self.data_loader.features.iloc[-self.config.sequence_length:].values\n",
    "        latest_data_scaled = self.data_loader.scaler.transform(latest_data)\n",
    "        \n",
    "        if model_name != 'LSTM_XGBoost':\n",
    "            # PyTorch model\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                X_tensor = torch.FloatTensor(latest_data_scaled).unsqueeze(0).to(self.config.device)\n",
    "                prediction = model(X_tensor).cpu().numpy().flatten()[0]\n",
    "        else:\n",
    "            # XGBoost ensemble - need base model predictions\n",
    "            base_models = ['LSTM', 'CNN_LSTM', 'Transformer']\n",
    "            base_predictions = []\n",
    "            \n",
    "            for base_model_name in base_models:\n",
    "                if base_model_name in self.trainer.models[horizon]:\n",
    "                    base_model = self.trainer.models[horizon][base_model_name]\n",
    "                    base_model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        X_tensor = torch.FloatTensor(latest_data_scaled).unsqueeze(0).to(self.config.device)\n",
    "                        base_pred = base_model(X_tensor).cpu().numpy().flatten()[0]\n",
    "                        base_predictions.append(base_pred)\n",
    "            \n",
    "            # Combine with flattened features\n",
    "            ensemble_features = np.concatenate([\n",
    "                latest_data_scaled.flatten(),\n",
    "                np.array(base_predictions)\n",
    "            ]).reshape(1, -1)\n",
    "            \n",
    "            dtest = xgb.DMatrix(ensemble_features)\n",
    "            prediction = model.predict(dtest)[0]\n",
    "        \n",
    "        return {\n",
    "            'horizon_minutes': horizon,\n",
    "            'model_used': model_name,\n",
    "            'predicted_price': float(prediction),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "'''  ## Running my custom run below ##\n",
    "def main():\n",
    "    \"\"\"Main function to run the cryptocurrency prediction system.\"\"\"\n",
    "    \n",
    "    # Example usage\n",
    "    print(\"Initializing Cryptocurrency Prediction System...\")\n",
    "    \n",
    "    # Initialize system (will fetch live data if no CSV provided)\n",
    "    system = CryptoPredictionSystem()\n",
    "    \n",
    "    # Configure which models to train (you can disable some for faster testing)\n",
    "    system.config.models_to_train = {\n",
    "        'LSTM': True,\n",
    "        'CNN_LSTM': True,\n",
    "        'Transformer': True,\n",
    "        'LSTM_XGBoost': True,\n",
    "        'RL_Agent': False  # Keep disabled for now\n",
    "    }\n",
    "    \n",
    "    # Optionally modify other configuration\n",
    "    system.config.epochs = 30  # Reduce for faster testing\n",
    "    system.config.prediction_horizons = [5, 10, 15]  # Test with fewer horizons\n",
    "    \n",
    "    # Run the complete experiment\n",
    "    results, output_dir = system.run_experiment(\"bitcoin_prediction_test\")\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\nExperiment completed successfully!\")\n",
    "        \n",
    "        # Example of making future predictions\n",
    "        print(\"\\nMaking sample predictions...\")\n",
    "        try:\n",
    "            for horizon in [5, 10]:\n",
    "                prediction = system.predict_future(horizon)\n",
    "                print(f\"Prediction for {horizon} minutes ahead: ${prediction['predicted_price']:.2f}\")\n",
    "                print(f\"Model used: {prediction['model_used']}\")\n",
    "                print(\"-\" * 30)\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Experiment failed. Check error messages above.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Additional utility functions for extending the system\n",
    "\n",
    "def load_external_features(csv_path: str, timestamp_col: str = 'Timestamp') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load external features from CSV file.\n",
    "    \n",
    "    This function can be used to load additional features like:\n",
    "    - Social sentiment data\n",
    "    - News sentiment scores\n",
    "    - Economic indicators\n",
    "    - Options flow data\n",
    "    - Funding rates\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to CSV file with external features\n",
    "        timestamp_col: Name of timestamp column\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with external features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df[timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading external features: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def merge_external_features(main_df: pd.DataFrame, external_df: pd.DataFrame, \n",
    "                          timestamp_col: str = 'Timestamp', \n",
    "                          merge_method: str = 'asof') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge external features with main dataset.\n",
    "    \n",
    "    Args:\n",
    "        main_df: Main price data DataFrame\n",
    "        external_df: External features DataFrame\n",
    "        timestamp_col: Timestamp column name\n",
    "        merge_method: Method for merging ('asof' for time-series, 'inner', 'left', etc.)\n",
    "        \n",
    "    Returns:\n",
    "        Merged DataFrame\n",
    "    \"\"\"\n",
    "    if merge_method == 'asof':\n",
    "        # Sort both DataFrames by timestamp\n",
    "        main_df = main_df.sort_values(timestamp_col)\n",
    "        external_df = external_df.sort_values(timestamp_col)\n",
    "        \n",
    "        # Perform as-of merge (forward-fill external features)\n",
    "        merged_df = pd.merge_asof(main_df, external_df, on=timestamp_col, direction='backward')\n",
    "    else:\n",
    "        merged_df = pd.merge(main_df, external_df, on=timestamp_col, how=merge_method)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def create_ensemble_prediction(models_dict: Dict, X_data: np.ndarray, \n",
    "                             weights: Optional[List[float]] = None) -> float:\n",
    "    \"\"\"\n",
    "    Create ensemble prediction from multiple models.\n",
    "    \n",
    "    Args:\n",
    "        models_dict: Dictionary of trained models\n",
    "        X_data: Input data for prediction\n",
    "        weights: Optional weights for each model (if None, uses equal weights)\n",
    "        \n",
    "    Returns:\n",
    "        Ensemble prediction\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    model_names = []\n",
    "    \n",
    "    for name, model in models_dict.items():\n",
    "        if hasattr(model, 'eval'):  # PyTorch model\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                X_tensor = torch.FloatTensor(X_data).unsqueeze(0)\n",
    "                pred = model(X_tensor).numpy().flatten()[0]\n",
    "        else:  # XGBoost or sklearn model\n",
    "            pred = model.predict(X_data.reshape(1, -1))[0]\n",
    "        \n",
    "        predictions.append(pred)\n",
    "        model_names.append(name)\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = np.ones(len(predictions)) / len(predictions)\n",
    "    else:\n",
    "        weights = np.array(weights)\n",
    "        weights = weights / weights.sum()  # Normalize\n",
    "    \n",
    "    ensemble_pred = np.sum(predictions * weights)\n",
    "    return float(ensemble_pred)\n",
    "\n",
    "\n",
    "# Example configuration for different use cases\n",
    "\n",
    "class QuickTestConfig(Config):\n",
    "    \"\"\"Configuration for quick testing with reduced parameters.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.epochs = 10\n",
    "        self.sequence_length = 30\n",
    "        self.prediction_horizons = [5, 10]\n",
    "        self.models_to_train = {\n",
    "            'LSTM': True,\n",
    "            'CNN_LSTM': False,\n",
    "            'Transformer': False,\n",
    "            'LSTM_XGBoost': False,\n",
    "            'RL_Agent': False\n",
    "        }\n",
    "\n",
    "\n",
    "class RealisticCryptoConfig(Config):\n",
    "    \"\"\"Realistic configuration for crypto prediction with proper scaling.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Shorter sequences for stability\n",
    "        self.sequence_length = 30  # 30 minutes lookback\n",
    "        \n",
    "        # Simpler models to prevent overfitting\n",
    "        self.lstm_hidden_size = 32\n",
    "        self.lstm_num_layers = 1\n",
    "        self.cnn_filters = 16\n",
    "        self.transformer_d_model = 32\n",
    "        self.transformer_nhead = 4\n",
    "        self.transformer_num_layers = 1\n",
    "        \n",
    "        # Conservative training\n",
    "        self.epochs = 50\n",
    "        self.batch_size = 64\n",
    "        self.learning_rate = 0.001\n",
    "        \n",
    "        # Very short horizons (more predictable)\n",
    "        self.prediction_horizons = [1, 3, 5]  # 1, 3, 5 minutes\n",
    "        \n",
    "        # Start with fewer models\n",
    "        self.models_to_train = {\n",
    "            'LSTM': True,\n",
    "            'CNN_LSTM': False,  # Disable complex models initially\n",
    "            'Transformer': False,\n",
    "            'LSTM_XGBoost': False,\n",
    "            'RL_Agent': False\n",
    "        }\n",
    "\n",
    "\n",
    "def run_debug_experiment():\n",
    "    \"\"\"Run experiment with debugging information.\"\"\"\n",
    "    print(\"Running DEBUG Cryptocurrency Prediction Experiment\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Use realistic configuration\n",
    "    system = CryptoPredictionSystem()\n",
    "    system.config = RealisticCryptoConfig()\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Load and inspect data\n",
    "        print(\"\\n1. Loading data...\")\n",
    "        data = system.data_loader.load_data()\n",
    "        print(f\"Raw data shape: {data.shape}\")\n",
    "        print(f\"Price range: ${data['Close'].min():.2f} - ${data['Close'].max():.2f}\")\n",
    "        print(f\"Price std: ${data['Close'].std():.2f}\")\n",
    "        \n",
    "        # Step 2: Engineer features\n",
    "        print(\"\\n2. Engineering features...\")\n",
    "        system.data_loader.engineer_features()\n",
    "        print(f\"Features shape: {system.data_loader.features.shape}\")\n",
    "        \n",
    "        # Step 3: Create targets and inspect\n",
    "        print(\"\\n3. Creating targets...\")\n",
    "        system.data_loader.create_targets()\n",
    "        \n",
    "        for horizon in system.config.prediction_horizons:\n",
    "            targets = system.data_loader.targets[horizon]\n",
    "            valid_targets = targets[~np.isnan(targets)]\n",
    "            print(f\"Horizon {horizon}min: mean={np.mean(valid_targets):.6f}, std={np.std(valid_targets):.6f}, range=[{np.min(valid_targets):.6f}, {np.max(valid_targets):.6f}]\")\n",
    "        \n",
    "        # Step 4: Train models\n",
    "        print(\"\\n4. Training models...\")\n",
    "        results = system.trainer.train_all_models(system.data_loader)\n",
    "        \n",
    "        return results, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Debug error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# Instructions for extending the system:\n",
    "\"\"\"\n",
    "EXTENDING THE SYSTEM:\n",
    "\n",
    "1. Adding New Models:\n",
    "   - Create a new model class inheriting from nn.Module (for PyTorch) or similar\n",
    "   - Add training logic in ModelTrainer.train_all_models()\n",
    "   - Add evaluation logic in ModelTrainer.evaluate_model()\n",
    "   - Enable in Config.models_to_train\n",
    "\n",
    "2. Adding New Features:\n",
    "   - Override CryptoPredictionSystem.add_custom_features()\n",
    "   - Use load_external_features() and merge_external_features() for external data\n",
    "   - Add feature engineering logic in DataLoader.engineer_features()\n",
    "\n",
    "3. Adding New Prediction Horizons:\n",
    "   - Modify Config.prediction_horizons list\n",
    "   - The system automatically handles multiple horizons\n",
    "\n",
    "4. Customizing Data Sources:\n",
    "   - Modify DataLoader.fetch_crypto_data() for different exchanges/symbols\n",
    "   - Override DataLoader.load_data() for different data formats\n",
    "\n",
    "5. Adding New Evaluation Metrics:\n",
    "   - Extend ModelTrainer.evaluate_model()\n",
    "   - Update ResultsAnalyzer for new visualizations\n",
    "\n",
    "6. Configuration Management:\n",
    "   - Create new Config subclasses for different use cases\n",
    "   - Save/load configurations using pickle or JSON\n",
    "\n",
    "Example Usage for Different Scenarios:\n",
    "\n",
    "# Quick test\n",
    "system = CryptoPredictionSystem()\n",
    "system.config = QuickTestConfig()\n",
    "results, output_dir = system.run_experiment(\"quick_test\")\n",
    "\n",
    "# With custom CSV data\n",
    "system = CryptoPredictionSystem(\"my_data.csv\")\n",
    "results, output_dir = system.run_experiment(\"custom_data_experiment\")\n",
    "\n",
    "# Production setup\n",
    "system = CryptoPredictionSystem()\n",
    "system.config = ProductionConfig()\n",
    "results, output_dir = system.run_experiment(\"production_run\")\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def main():\n",
    "    \"\"\"Main function to run the cryptocurrency prediction system.\"\"\"\n",
    "    \n",
    "    # Example usage\n",
    "    print(\"Initializing Cryptocurrency Prediction System...\")\n",
    "    \n",
    "    # Initialize system (will fetch live data if no CSV provided)\n",
    "    system = CryptoPredictionSystem()\n",
    "    \n",
    "    # Configure which models to train (you can disable some for faster testing)\n",
    "    system.config.models_to_train = {\n",
    "        'LSTM': True,\n",
    "        'CNN_LSTM': True,\n",
    "        'Transformer': True,\n",
    "        'LSTM_XGBoost': True,\n",
    "        'RL_Agent': False  # Keep disabled for now\n",
    "    }\n",
    "    \n",
    "    # Optionally modify other configuration\n",
    "    system.config.epochs = 30  # Reduce for faster testing\n",
    "    system.config.prediction_horizons = [5, 10, 15]  # Test with fewer horizons\n",
    "    \n",
    "    # Run the complete experiment\n",
    "    results, output_dir = system.run_experiment(\"bitcoin_prediction_test\")\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\nExperiment completed successfully!\")\n",
    "        \n",
    "        # Example of making future predictions\n",
    "        print(\"\\nMaking sample predictions...\")\n",
    "        try:\n",
    "            for horizon in [5, 10]:\n",
    "                prediction = system.predict_future(horizon)\n",
    "                print(f\"Prediction for {horizon} minutes ahead: ${prediction['predicted_price']:.2f}\")\n",
    "                print(f\"Model used: {prediction['model_used']}\")\n",
    "                print(\"-\" * 30)\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Experiment failed. Check error messages above.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CRYPTOCURRENCY PRICE PREDICTION SYSTEM\n",
      "============================================================\n",
      "\n",
      "1. Loading and preparing data...\n",
      "Loading data from ./3_months_of_days_of_crypto_(1m).csv\n",
      "Loaded data shape: (133917, 6)\n",
      "Date range: 2024-09-07 00:38:00 to 2024-12-09 23:59:00\n",
      "Engineering features...\n",
      "Feature engineering complete. Shape: (115593, 30)\n",
      "Creating target variables...\n",
      "Target variables created for horizons: [5, 10, 15]\n",
      "Final feature shape: (115578, 28)\n",
      "Available features: ['Open', 'High', 'Low', 'Volume', 'Price_Change', 'Price_Range', 'Price_Position', 'SMA_5', 'Price_to_SMA_5', 'SMA_10', 'Price_to_SMA_10', 'SMA_20', 'Price_to_SMA_20', 'EMA_12', 'EMA_26', 'MACD', 'BB_Middle', 'BB_Std', 'BB_Upper', 'BB_Lower', 'BB_Position', 'RSI', 'Volume_SMA', 'Volume_Ratio', 'Volatility', 'Hour', 'DayOfWeek', 'IsWeekend']\n",
      "\n",
      "2. Training models...\n",
      "Starting model training...\n",
      "\n",
      "==================================================\n",
      "Training models for 5-minute horizon\n",
      "==================================================\n",
      "Splitting data for 5-minute horizon...\n",
      "Training LSTM for 5-minute horizon...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m system\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;66;03m#30 # Reduce for faster testing\u001b[39;00m\n\u001b[0;32m     14\u001b[0m system\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_horizons \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m]  \u001b[38;5;66;03m# Test with fewer horizons\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m results, output_dir \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcustom_experiment_for_365_days_of_1_minute_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExperiment completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 881\u001b[0m, in \u001b[0;36mCryptoPredictionSystem.run_experiment\u001b[1;34m(self, experiment_name)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# Step 2: Train all models\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2. Training models...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 881\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_all_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;66;03m# Step 3: Analyze results\u001b[39;00m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m3. Analyzing results...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 568\u001b[0m, in \u001b[0;36mModelTrainer.train_all_models\u001b[1;34m(self, data_loader)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodels_to_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    563\u001b[0m     lstm_model \u001b[38;5;241m=\u001b[39m LSTMModel(\n\u001b[0;32m    564\u001b[0m         input_size\u001b[38;5;241m=\u001b[39minput_size,\n\u001b[0;32m    565\u001b[0m         hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlstm_hidden_size,\n\u001b[0;32m    566\u001b[0m         num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlstm_num_layers\n\u001b[0;32m    567\u001b[0m     )\n\u001b[1;32m--> 568\u001b[0m     lstm_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_pytorch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLSTM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     lstm_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_model(\n\u001b[0;32m    572\u001b[0m         lstm_model, data_splits[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test\u001b[39m\u001b[38;5;124m'\u001b[39m], data_splits[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m, horizon\n\u001b[0;32m    573\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[13], line 400\u001b[0m, in \u001b[0;36mModelTrainer.train_pytorch_model\u001b[1;34m(self, model, train_loader, val_loader, horizon, model_name)\u001b[0m\n\u001b[0;32m    398\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    399\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m--> 400\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    401\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m    403\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mikey\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:101\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor betas[1] must be 1-element\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m     89\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m     90\u001b[0m     betas\u001b[38;5;241m=\u001b[39mbetas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m     decoupled_weight_decay\u001b[38;5;241m=\u001b[39mdecoupled_weight_decay,\n\u001b[0;32m    100\u001b[0m )\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32mc:\\Users\\mikey\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:400\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    397\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mikey\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_compile.py:46\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m disable_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dynamo_disable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# We can safely turn off functools.wraps here because the inner\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# already wraps fn in the outer scope.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive, wrapping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\mikey\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\__init__.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, eval_frame, resume_execution\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[1;32mc:\\Users\\mikey\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallbackTrigger\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:969\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1091\u001b[0m, in \u001b[0;36mpath_stats\u001b[1;34m(self, path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use your own CSV file\n",
    "system = CryptoPredictionSystem(\"./3_months_of_days_of_crypto_(1m).csv\")\n",
    "\n",
    "system.config.models_to_train = {\n",
    "        'LSTM': True,\n",
    "        'CNN_LSTM': True,\n",
    "        'Transformer': True,\n",
    "        'LSTM_XGBoost': True,\n",
    "        'RL_Agent': False  # Keep disabled for now\n",
    "    }\n",
    "\n",
    "# Optionally modify other configuration\n",
    "system.config.epochs = 20 #30 # Reduce for faster testing\n",
    "system.config.prediction_horizons = [5, 10, 15]  # Test with fewer horizons\n",
    "\n",
    "results, output_dir = system.run_experiment(\"custom_experiment_for_365_days_of_1_minute_data\")\n",
    "\n",
    "if results:\n",
    "    print(\"\\nExperiment completed successfully!\")\n",
    "\n",
    "    # Example of making future predictions\n",
    "    print(\"\\nMaking sample predictions...\")\n",
    "    try:\n",
    "        for horizon in [5, 10]:\n",
    "            prediction = system.predict_future(horizon)\n",
    "            print(f\"Prediction for {horizon} minutes ahead: ${prediction['predicted_price']:.2f}\")\n",
    "            print(f\"Model used: {prediction['model_used']}\")\n",
    "            print(\"-\" * 30)\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Experiment failed. Check error messages above.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8221376,
     "sourceId": 12988758,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a388e0ebdc84ec3be09ce41633d5c07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2101f259b5b845898861b8d8cb372a1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Username:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_316ed3ef48fb4fb0b4d2cb9bd69f32bb",
      "placeholder": "​",
      "style": "IPY_MODEL_b2c3361ded084e6587dad9f69e67eb05",
      "value": "mikewschmidt"
     }
    },
    "3140d096799341b18e6173cd9d3130b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b46ba47271d407a833bf2442a0e9fa3",
      "placeholder": "​",
      "style": "IPY_MODEL_8903a21e3d224f658b16f681db367d6e",
      "value": "Kaggle credentials successfully validated."
     }
    },
    "316ed3ef48fb4fb0b4d2cb9bd69f32bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a9b484eac9e4aff97012ab630d82552": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "4058f94f750e4bcfb254850814513eb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_7e6e8fbc01864124b90a3b69a2afbecb",
      "style": "IPY_MODEL_3a9b484eac9e4aff97012ab630d82552",
      "tooltip": ""
     }
    },
    "4741abde921f4498b36838d9189bdb9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "4bc7e65dfb5d4b00a7a358d8882ca074": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4073318641446769d0af98c9deb6508",
      "placeholder": "​",
      "style": "IPY_MODEL_5a2cc1e2896b43f4897d0c87ade36963",
      "value": "\n<b>Thank You</b></center>"
     }
    },
    "575d6f04956f4ba78a079c98540420c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a29762b99564463980cd38797a86bd67",
      "placeholder": "​",
      "style": "IPY_MODEL_cb6da7108884416e96750a01ca70c115",
      "value": "Connecting..."
     }
    },
    "5a2cc1e2896b43f4897d0c87ade36963": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5fe34be08a604d04a38b4ebbf1a12bc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3140d096799341b18e6173cd9d3130b6"
      ],
      "layout": "IPY_MODEL_4741abde921f4498b36838d9189bdb9d"
     }
    },
    "7b46ba47271d407a833bf2442a0e9fa3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e6e8fbc01864124b90a3b69a2afbecb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8903a21e3d224f658b16f681db367d6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1cae1a2258345cc820426600a284c2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a29762b99564463980cd38797a86bd67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a79eb373af6147c3b898fba907ea06e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af330227150b44e4aca950286f9839ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a79eb373af6147c3b898fba907ea06e7",
      "placeholder": "​",
      "style": "IPY_MODEL_a1cae1a2258345cc820426600a284c2c",
      "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
     }
    },
    "b2c3361ded084e6587dad9f69e67eb05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4073318641446769d0af98c9deb6508": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7d6c398add9491d820b2f5d74aa6bfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_d41f0e9fae4d4cb4b0f910f438c0f4a5",
      "placeholder": "​",
      "style": "IPY_MODEL_0a388e0ebdc84ec3be09ce41633d5c07",
      "value": ""
     }
    },
    "cb6da7108884416e96750a01ca70c115": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d41f0e9fae4d4cb4b0f910f438c0f4a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
