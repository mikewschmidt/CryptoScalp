{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T18:24:19.721498Z",
     "iopub.status.busy": "2025-09-07T18:24:19.721196Z",
     "iopub.status.idle": "2025-09-07T18:27:42.296023Z",
     "shell.execute_reply": "2025-09-07T18:27:42.294734Z",
     "shell.execute_reply.started": "2025-09-07T18:24:19.721476Z"
    },
    "id": "sKqFV1x2iF30",
    "outputId": "2163a224-e048-408d-8c62-1df683cf8279"
   },
   "outputs": [],
   "source": [
    "!run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#####\n",
    "#####  VERSION 8\n",
    "#####\n",
    "#####\n",
    "\"\"\"\n",
    "Improved Cryptocurrency Short-term Price Prediction System\n",
    "=========================================================\n",
    "\n",
    "A fixed and improved system for cryptocurrency price prediction focusing on:\n",
    "- Predicting returns instead of raw prices\n",
    "- Preventing data leakage\n",
    "- Using simpler, more robust models\n",
    "- Better feature engineering\n",
    "\n",
    "Author: AI Assistant\n",
    "License: MIT\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Data handling and preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy import stats\n",
    "\n",
    "# Deep learning frameworks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# XGBoost for ensemble\n",
    "import xgboost as xgb\n",
    "\n",
    "# Data source\n",
    "import ccxt\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available, using CPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    device = torch.device(\"cuda\")  # Use the GPU\n",
    "else:\n",
    "    print(\"GPU is not available, using CPU.\")\n",
    "    device = torch.device(\"cpu\")  # Use the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImprovedConfig:\n",
    "    \"\"\"Improved configuration class with realistic parameters.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Data parameters\n",
    "        self.csv_file = None\n",
    "        self.timestamp_col = 'Timestamp'\n",
    "        self.required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        self.target_col = 'Close'\n",
    "        \n",
    "        # FIXED: Much shorter prediction horizons (more realistic)\n",
    "        self.prediction_horizons = [1, 2, 3]  # 1, 2, 3 minutes only\n",
    "        \n",
    "        # FIXED: Shorter sequence length for crypto's high volatility\n",
    "        self.sequence_length = 20  # 20 minutes lookback\n",
    "        \n",
    "        # FIXED: Simpler model parameters to prevent overfitting\n",
    "        self.lstm_hidden_size = 32\n",
    "        self.lstm_num_layers = 1\n",
    "        self.dropout_rate = 0.3\n",
    "        \n",
    "        # Training parameters\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 100\n",
    "        self.learning_rate = 0.0005  # Lower learning rate\n",
    "        \n",
    "        # FIXED: Better data splits with more validation data\n",
    "        self.train_ratio = 0.6\n",
    "        self.val_ratio = 0.2\n",
    "        self.test_ratio = 0.2\n",
    "        \n",
    "        # Device\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Start with fewer models\n",
    "        self.models_to_train = {\n",
    "            'SimpleLSTM': True,\n",
    "            'BaselineModel': True,  # Always include baseline\n",
    "            'XGBoost': False,  # Can enable later\n",
    "        }\n",
    "        \n",
    "        # Output directory\n",
    "        self.output_dir = 'improved_crypto_results'\n",
    "\n",
    "\n",
    "class ImprovedDataLoader:\n",
    "    \"\"\"Improved data loader with better preprocessing and feature engineering.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ImprovedConfig):\n",
    "        self.config = config\n",
    "        self.scaler = RobustScaler()  # More robust to outliers\n",
    "        self.feature_selector = None\n",
    "        self.data = None\n",
    "        self.features = None\n",
    "        self.targets = {}\n",
    "        \n",
    "    def fetch_crypto_data(self, symbol='BTC/USD', timeframe='1m', limit=1000):\n",
    "        \"\"\"Fetch real cryptocurrency data using CCXT.\"\"\"\n",
    "        print(f\"Fetching {symbol} data from Coinbase...\")\n",
    "        \n",
    "        try:\n",
    "            exchange = ccxt.coinbase()\n",
    "            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)\n",
    "            \n",
    "            df = pd.DataFrame(ohlcv, columns=['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "            df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='ms')\n",
    "            \n",
    "            print(f\"Successfully fetched {len(df)} candles\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def check_data_quality(self):\n",
    "        \"\"\"Check for data quality issues.\"\"\"\n",
    "        print(\"Checking data quality...\")\n",
    "        \n",
    "        # Check for duplicate timestamps\n",
    "        duplicates = self.data[self.config.timestamp_col].duplicated().sum()\n",
    "        print(f\"Duplicate timestamps: {duplicates}\")\n",
    "        if duplicates > 0:\n",
    "            self.data = self.data.drop_duplicates(subset=[self.config.timestamp_col])\n",
    "            print(\"Removed duplicate timestamps\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing = self.data[self.config.required_cols].isnull().sum()\n",
    "        print(f\"Missing values per column:\\n{missing}\")\n",
    "        \n",
    "        # Check for extreme outliers (>20% price changes)\n",
    "        price_changes = self.data['Close'].pct_change()\n",
    "        extreme_changes = (abs(price_changes) > 0.2).sum()\n",
    "        print(f\"Extreme price changes (>20%): {extreme_changes}\")\n",
    "        \n",
    "        # Remove extreme outliers\n",
    "        if extreme_changes > 0:\n",
    "            valid_changes = abs(price_changes) <= 0.2\n",
    "            self.data = self.data[valid_changes | price_changes.isna()].reset_index(drop=True)\n",
    "            print(f\"Removed {extreme_changes} extreme outliers\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def load_data(self, csv_file: Optional[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"Load and validate data.\"\"\"\n",
    "        if csv_file and os.path.exists(csv_file):\n",
    "            print(f\"Loading data from {csv_file}\")\n",
    "            self.data = pd.read_csv(csv_file)\n",
    "            self.data[self.config.timestamp_col] = pd.to_datetime(self.data[self.config.timestamp_col])\n",
    "        else:\n",
    "            print(\"No CSV file provided or file not found. Fetching live data...\")\n",
    "            self.data = self.fetch_crypto_data()\n",
    "            \n",
    "            if self.data is None:\n",
    "                raise ValueError(\"Could not load or fetch data\")\n",
    "        \n",
    "        # Ensure required columns exist\n",
    "        missing_cols = [col for col in self.config.required_cols if col not in self.data.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Sort by timestamp and reset index\n",
    "        self.data = self.data.sort_values(self.config.timestamp_col).reset_index(drop=True)\n",
    "        \n",
    "        # Check data quality\n",
    "        self.check_data_quality()\n",
    "        \n",
    "        print(f\"Final data shape: {self.data.shape}\")\n",
    "        print(f\"Date range: {self.data[self.config.timestamp_col].min()} to {self.data[self.config.timestamp_col].max()}\")\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def engineer_features(self) -> pd.DataFrame:\n",
    "        \"\"\"FIXED: Improved feature engineering without data leakage.\"\"\"\n",
    "        print(\"Engineering features...\")\n",
    "        \n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # CRITICAL FIX: Calculate returns instead of using raw prices\n",
    "        df['Returns'] = df['Close'].pct_change()\n",
    "        df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "        \n",
    "        # Volatility features (very important for crypto)\n",
    "        df['Volatility_5'] = df['Returns'].rolling(5).std()\n",
    "        df['Volatility_20'] = df['Returns'].rolling(20).std()\n",
    "        df['Volatility_Ratio'] = df['Volatility_5'] / df['Volatility_20']\n",
    "        \n",
    "        # Volume-price features\n",
    "        df['Volume_MA'] = df['Volume'].rolling(20).mean()\n",
    "        df['Volume_Ratio'] = df['Volume'] / df['Volume_MA']\n",
    "        df['Volume_Price_Trend'] = df['Volume'] * df['Returns']\n",
    "        \n",
    "        # Price position features\n",
    "        df['Price_Position'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'])\n",
    "        df['Spread_Ratio'] = (df['High'] - df['Low']) / df['Close']\n",
    "        \n",
    "        # Momentum features\n",
    "        for period in [5, 10, 20]:\n",
    "            df[f'Momentum_{period}'] = df['Close'] / df['Close'].shift(period) - 1\n",
    "            df[f'SMA_{period}'] = df['Close'].rolling(period).mean()\n",
    "            df[f'Price_to_SMA_{period}'] = df['Close'] / df[f'SMA_{period}'] - 1\n",
    "        \n",
    "        # RSI (Relative Strength Index)\n",
    "        delta = df['Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / loss\n",
    "        df['RSI'] = 100 - (100 / (1 + rs))\n",
    "        df['RSI_Normalized'] = (df['RSI'] - 50) / 50  # Normalize RSI\n",
    "        \n",
    "        # Lagged features (very important for time series)\n",
    "        for lag in [1, 2, 3, 5]:\n",
    "            df[f'Returns_Lag_{lag}'] = df['Returns'].shift(lag)\n",
    "            df[f'Volume_Lag_{lag}'] = np.log(df['Volume']).shift(lag)  # Log transform volume\n",
    "        \n",
    "        # Order book proxy features\n",
    "        df['Upper_Shadow'] = (df['High'] - df[['Open', 'Close']].max(axis=1)) / df['Close']\n",
    "        df['Lower_Shadow'] = (df[['Open', 'Close']].min(axis=1) - df['Low']) / df['Close']\n",
    "        df['Body_Size'] = abs(df['Close'] - df['Open']) / df['Close']\n",
    "        \n",
    "        # Time-based features (careful not to leak information)\n",
    "        df['Hour'] = df[self.config.timestamp_col].dt.hour\n",
    "        df['DayOfWeek'] = df[self.config.timestamp_col].dt.dayofweek\n",
    "        df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(int)\n",
    "        \n",
    "        # CRITICAL: Remove any rows with NaN values\n",
    "        initial_rows = len(df)\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "        removed_rows = initial_rows - len(df)\n",
    "        print(f\"Removed {removed_rows} rows with NaN values\")\n",
    "        \n",
    "        # Select only engineered features (not raw OHLCV)\n",
    "        feature_cols = [col for col in df.columns \n",
    "                       if col not in [self.config.timestamp_col, 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "                       and not col.startswith('SMA_')]  # Remove intermediate calculations\n",
    "        \n",
    "        self.features = df[feature_cols].copy()\n",
    "        self.data = df\n",
    "        \n",
    "        print(f\"Feature engineering complete. Features: {len(feature_cols)}, Rows: {len(df)}\")\n",
    "        print(f\"Feature list: {feature_cols}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_targets(self) -> Dict[int, np.ndarray]:\n",
    "        \"\"\"FIXED: Create percentage return targets instead of raw prices.\"\"\"\n",
    "        print(\"Creating target variables (percentage returns)...\")\n",
    "        \n",
    "        targets = {}\n",
    "        current_price = self.data[self.config.target_col]\n",
    "        \n",
    "        for horizon in self.config.prediction_horizons:\n",
    "            future_price = current_price.shift(-horizon)\n",
    "            \n",
    "            # CRITICAL FIX: Predict percentage returns instead of raw prices\n",
    "            price_returns = (future_price - current_price) / current_price\n",
    "            targets[horizon] = price_returns.values\n",
    "            \n",
    "            print(f\"Horizon {horizon}min: mean return = {np.nanmean(price_returns):.6f}, \"\n",
    "                  f\"std = {np.nanstd(price_returns):.6f}\")\n",
    "        \n",
    "        # Remove rows without valid targets\n",
    "        max_horizon = max(self.config.prediction_horizons)\n",
    "        for horizon in targets:\n",
    "            targets[horizon] = targets[horizon][:-max_horizon]\n",
    "        \n",
    "        # Update features to match target length\n",
    "        self.features = self.features.iloc[:-max_horizon].copy()\n",
    "        \n",
    "        self.targets = targets\n",
    "        print(f\"Targets created for horizons: {list(targets.keys())}\")\n",
    "        \n",
    "        return targets\n",
    "    \n",
    "    def feature_selection(self, X: np.ndarray, y: np.ndarray, k: int = 20):\n",
    "        \"\"\"Select the most predictive features.\"\"\"\n",
    "        print(f\"Selecting top {k} features...\")\n",
    "        \n",
    "        # Remove features with zero variance\n",
    "        non_zero_var = X.var(axis=0) > 1e-6\n",
    "        X_filtered = X[:, non_zero_var]\n",
    "        feature_names_filtered = [name for i, name in enumerate(self.features.columns) if non_zero_var[i]]\n",
    "        \n",
    "        # Select best features using F-statistic\n",
    "        selector = SelectKBest(score_func=f_regression, k=min(k, X_filtered.shape[1]))\n",
    "        X_selected = selector.fit_transform(X_filtered, y)\n",
    "        \n",
    "        # Get selected feature names\n",
    "        selected_mask = selector.get_support()\n",
    "        selected_features = [feature_names_filtered[i] for i, selected in enumerate(selected_mask) if selected]\n",
    "        \n",
    "        print(f\"Selected features: {selected_features}\")\n",
    "        \n",
    "        self.feature_selector = selector\n",
    "        self.selected_feature_names = selected_features\n",
    "        \n",
    "        return X_selected, selected_features\n",
    "    \n",
    "    def prepare_sequences(self, features: np.ndarray, targets: np.ndarray, \n",
    "                         sequence_length: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Prepare sequential data for time series models.\"\"\"\n",
    "        X, y = [], []\n",
    "        \n",
    "        for i in range(sequence_length, len(features)):\n",
    "            X.append(features[i-sequence_length:i])\n",
    "            y.append(targets[i])\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def split_data(self, horizon: int) -> Dict[str, Any]:\n",
    "        \"\"\"FIXED: Proper time series split with feature selection.\"\"\"\n",
    "        print(f\"Splitting data for {horizon}-minute horizon...\")\n",
    "        \n",
    "        # Get targets and remove NaN values\n",
    "        targets = self.targets[horizon]\n",
    "        valid_indices = ~np.isnan(targets)\n",
    "        \n",
    "        features_clean = self.features[valid_indices].values\n",
    "        targets_clean = targets[valid_indices]\n",
    "        \n",
    "        print(f\"Clean data shape: {features_clean.shape}, targets: {len(targets_clean)}\")\n",
    "        \n",
    "        # Feature selection on training data only\n",
    "        n_samples = len(features_clean)\n",
    "        train_end = int(n_samples * self.config.train_ratio)\n",
    "        \n",
    "        X_train_for_selection = features_clean[:train_end]\n",
    "        y_train_for_selection = targets_clean[:train_end]\n",
    "        \n",
    "        # Remove any remaining NaN values from training data\n",
    "        train_valid = ~(np.isnan(X_train_for_selection).any(axis=1) | np.isnan(y_train_for_selection))\n",
    "        X_train_for_selection = X_train_for_selection[train_valid]\n",
    "        y_train_for_selection = y_train_for_selection[train_valid]\n",
    "        \n",
    "        # Perform feature selection\n",
    "        X_selected, selected_features = self.feature_selection(\n",
    "            X_train_for_selection, y_train_for_selection, k=15\n",
    "        )\n",
    "        \n",
    "        # Apply feature selection to all data\n",
    "        features_selected = self.feature_selector.transform(features_clean)\n",
    "        \n",
    "        # Scale features\n",
    "        features_scaled = self.scaler.fit_transform(features_selected)\n",
    "        \n",
    "        # Time series split\n",
    "        val_end = int(n_samples * (self.config.train_ratio + self.config.val_ratio))\n",
    "        \n",
    "        # Create sequences\n",
    "        X_seq, y_seq = self.prepare_sequences(features_scaled, targets_clean, self.config.sequence_length)\n",
    "        \n",
    "        # Adjust indices for sequences\n",
    "        train_end_seq = max(0, train_end - self.config.sequence_length)\n",
    "        val_end_seq = max(train_end_seq, val_end - self.config.sequence_length)\n",
    "        \n",
    "        # Split sequences\n",
    "        X_train = X_seq[:train_end_seq]\n",
    "        y_train = y_seq[:train_end_seq]\n",
    "        X_val = X_seq[train_end_seq:val_end_seq]\n",
    "        y_val = y_seq[train_end_seq:val_end_seq]\n",
    "        X_test = X_seq[val_end_seq:]\n",
    "        y_test = y_seq[val_end_seq:]\n",
    "        \n",
    "        # Also prepare non-sequential data for traditional ML models\n",
    "        X_train_flat = features_scaled[self.config.sequence_length:train_end]\n",
    "        X_val_flat = features_scaled[train_end:val_end]\n",
    "        X_test_flat = features_scaled[val_end:]\n",
    "        \n",
    "        y_train_flat = targets_clean[self.config.sequence_length:train_end]\n",
    "        y_val_flat = targets_clean[train_end:val_end]\n",
    "        y_test_flat = targets_clean[val_end:]\n",
    "        \n",
    "        print(f\"Data splits - Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "        \n",
    "        return {\n",
    "            'X_train': X_train, 'y_train': y_train,\n",
    "            'X_val': X_val, 'y_val': y_val,\n",
    "            'X_test': X_test, 'y_test': y_test,\n",
    "            'X_train_flat': X_train_flat, 'y_train_flat': y_train_flat,\n",
    "            'X_val_flat': X_val_flat, 'y_val_flat': y_val_flat,\n",
    "            'X_test_flat': X_test_flat, 'y_test_flat': y_test_flat,\n",
    "            'selected_features': selected_features\n",
    "        }\n",
    "\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    \"\"\"FIXED: Simplified LSTM model to prevent overfitting.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size: int, hidden_size: int = 32, dropout: float = 0.3):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Single LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=1, \n",
    "                           batch_first=True, dropout=0.0)  # No dropout in single layer\n",
    "        \n",
    "        # Regularization layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize weights for better convergence.\"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                torch.nn.init.xavier_uniform_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                torch.nn.init.orthogonal_(param.data)\n",
    "            elif 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Take last output\n",
    "        out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Apply batch normalization (only if batch size > 1)\n",
    "        if batch_size > 1:\n",
    "            out = self.batch_norm(out)\n",
    "        \n",
    "        # Apply dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Final prediction\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class BaselineModel:\n",
    "    \"\"\"Simple baseline models for comparison.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.last_value = 0\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"Fit baseline model.\"\"\"\n",
    "        # For random walk, we don't need to fit anything\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict using simple baseline (predict no change).\"\"\"\n",
    "        return np.zeros(len(X_test))  # Predict no price change\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Baseline_RandomWalk\"\n",
    "\n",
    "\n",
    "class ImprovedModelTrainer:\n",
    "    \"\"\"FIXED: Improved model trainer with better regularization and validation.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ImprovedConfig):\n",
    "        self.config = config\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def train_pytorch_model(self, model, train_loader, val_loader, horizon: int, model_name: str):\n",
    "        \"\"\"FIXED: Improved training with better regularization and early stopping.\"\"\"\n",
    "        print(f\"Training {model_name} for {horizon}-minute horizon...\")\n",
    "        \n",
    "        model = model.to(self.config.device)\n",
    "        \n",
    "        # Use SmoothL1Loss (more robust than MSE)\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        \n",
    "        # Adam optimizer with weight decay\n",
    "        optimizer = optim.Adam(model.parameters(), lr=self.config.learning_rate, weight_decay=1e-5)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.7, patience=10, min_lr=1e-6\n",
    "        )\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        for epoch in range(self.config.epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            train_batches = 0\n",
    "            \n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X = batch_X.to(self.config.device)\n",
    "                batch_y = batch_y.to(self.config.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs.squeeze(), batch_y)\n",
    "                \n",
    "                # Add L1 regularization\n",
    "                l1_reg = sum(param.abs().sum() for param in model.parameters())\n",
    "                loss = loss + 1e-6 * l1_reg\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                train_batches += 1\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_X, batch_y in val_loader:\n",
    "                    batch_X = batch_X.to(self.config.device)\n",
    "                    batch_y = batch_y.to(self.config.device)\n",
    "                    outputs = model(batch_X)\n",
    "                    val_loss += criterion(outputs.squeeze(), batch_y).item()\n",
    "                    val_batches += 1\n",
    "            \n",
    "            # Calculate average losses\n",
    "            avg_train_loss = train_loss / train_batches if train_batches > 0 else float('inf')\n",
    "            avg_val_loss = val_loss / val_batches if val_batches > 0 else float('inf')\n",
    "            \n",
    "            train_losses.append(avg_train_loss)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            \n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            # Early stopping and model saving\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(model.state_dict(), f'{model_name}_{horizon}min_best.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if epoch % 20 == 0:\n",
    "                print(f'Epoch {epoch}: Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}')\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= 25:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "            \n",
    "            # Check for severe overfitting\n",
    "            if len(train_losses) > 30:\n",
    "                if val_losses[-1] > val_losses[-20] * 1.1:\n",
    "                    print(\"Severe overfitting detected, stopping training\")\n",
    "                    break\n",
    "        \n",
    "        # Load best model\n",
    "        model.load_state_dict(torch.load(f'{model_name}_{horizon}min_best.pth'))\n",
    "        return model\n",
    "    \n",
    "    def train_xgboost_model(self, X_train, y_train, X_val, y_val, horizon: int):\n",
    "        \"\"\"Train XGBoost model with proper regularization.\"\"\"\n",
    "        print(f\"Training XGBoost for {horizon}-minute horizon...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        \n",
    "        # Conservative parameters to prevent overfitting\n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'max_depth': 4,  # Shallow trees\n",
    "            'learning_rate': 0.05,  # Low learning rate\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'reg_alpha': 0.1,  # L1 regularization\n",
    "            'reg_lambda': 0.1,  # L2 regularization\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        # Train model\n",
    "        model = xgb.train(\n",
    "            params, dtrain,\n",
    "            num_boost_round=200,\n",
    "            evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "            early_stopping_rounds=20,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def evaluate_model(self, model, X_test, y_test, model_name: str, horizon: int, is_pytorch: bool = True):\n",
    "        \"\"\"Evaluate model performance with multiple metrics.\"\"\"\n",
    "        if is_pytorch:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                if isinstance(X_test, np.ndarray):\n",
    "                    X_test_tensor = torch.FloatTensor(X_test).to(self.config.device)\n",
    "                else:\n",
    "                    X_test_tensor = X_test.to(self.config.device)\n",
    "                predictions = model(X_test_tensor).cpu().numpy().flatten()\n",
    "        elif hasattr(model, 'predict'):  # XGBoost or sklearn\n",
    "            if isinstance(X_test, np.ndarray):\n",
    "                if hasattr(model, 'predict'):  # XGBoost\n",
    "                    dtest = xgb.DMatrix(X_test)\n",
    "                    predictions = model.predict(dtest)\n",
    "                else:\n",
    "                    predictions = model.predict(X_test)\n",
    "            else:\n",
    "                predictions = model.predict(X_test)\n",
    "        else:  # BaselineModel\n",
    "            predictions = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        # Additional metrics for financial data\n",
    "        # Directional accuracy (did we predict the right direction?)\n",
    "        actual_direction = np.sign(y_test)\n",
    "        pred_direction = np.sign(predictions)\n",
    "        directional_accuracy = np.mean(actual_direction == pred_direction)\n",
    "        \n",
    "        return {\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'Directional_Accuracy': directional_accuracy,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "    \n",
    "    def create_baseline_predictions(self, y_test):\n",
    "        \"\"\"Create baseline predictions for comparison.\"\"\"\n",
    "        # Random walk baseline (predict no change)\n",
    "        return np.zeros_like(y_test)\n",
    "    \n",
    "    def train_all_models(self, data_loader: ImprovedDataLoader):\n",
    "        \"\"\"Train all enabled models with proper evaluation.\"\"\"\n",
    "        print(\"Starting model training with improved methodology...\")\n",
    "        \n",
    "        os.makedirs(self.config.output_dir, exist_ok=True)\n",
    "        \n",
    "        for horizon in self.config.prediction_horizons:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Training models for {horizon}-minute horizon\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            # Get data splits\n",
    "            data_splits = data_loader.split_data(horizon)\n",
    "            \n",
    "            if len(data_splits['X_train']) < 50:\n",
    "                print(f\"Not enough training data for {horizon}-minute horizon. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Prepare PyTorch data loaders\n",
    "            if len(data_splits['X_train']) > 0:\n",
    "                X_train_tensor = torch.FloatTensor(data_splits['X_train'])\n",
    "                y_train_tensor = torch.FloatTensor(data_splits['y_train'])\n",
    "                train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)\n",
    "                \n",
    "                X_val_tensor = torch.FloatTensor(data_splits['X_val'])\n",
    "                y_val_tensor = torch.FloatTensor(data_splits['y_val'])\n",
    "                val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size, shuffle=False)\n",
    "            \n",
    "            input_size = data_splits['X_train'].shape[2] if len(data_splits['X_train'].shape) > 2 else data_splits['X_train'].shape[1]\n",
    "            horizon_results = {}\n",
    "            \n",
    "            # Initialize models dict for this horizon\n",
    "            if horizon not in self.models:\n",
    "                self.models[horizon] = {}\n",
    "            \n",
    "            # Train Baseline Model (always include)\n",
    "            if self.config.models_to_train['BaselineModel']:\n",
    "                print(\"Training Baseline Model...\")\n",
    "                baseline_model = BaselineModel()\n",
    "                baseline_model.fit(data_splits['X_train_flat'], data_splits['y_train_flat'])\n",
    "                \n",
    "                # Evaluate\n",
    "                baseline_results = self.evaluate_model(\n",
    "                    baseline_model, data_splits['X_test_flat'], data_splits['y_test_flat'],\n",
    "                    'Baseline', horizon, is_pytorch=False\n",
    "                )\n",
    "                horizon_results['Baseline'] = baseline_results\n",
    "                self.models[horizon]['Baseline'] = baseline_model\n",
    "            \n",
    "            # Train Simple LSTM\n",
    "            if self.config.models_to_train['SimpleLSTM'] and len(data_splits['X_train']) > 0:\n",
    "                lstm_model = SimpleLSTM(\n",
    "                    input_size=input_size,\n",
    "                    hidden_size=self.config.lstm_hidden_size,\n",
    "                    dropout=self.config.dropout_rate\n",
    "                )\n",
    "                \n",
    "                lstm_model = self.train_pytorch_model(\n",
    "                    lstm_model, train_loader, val_loader, horizon, 'SimpleLSTM'\n",
    "                )\n",
    "                \n",
    "                # Evaluate\n",
    "                lstm_results = self.evaluate_model(\n",
    "                    lstm_model, data_splits['X_test'], data_splits['y_test'], \n",
    "                    'SimpleLSTM', horizon\n",
    "                )\n",
    "                horizon_results['SimpleLSTM'] = lstm_results\n",
    "                self.models[horizon]['SimpleLSTM'] = lstm_model\n",
    "            \n",
    "            # Train XGBoost\n",
    "            if self.config.models_to_train['XGBoost']:\n",
    "                xgb_model = self.train_xgboost_model(\n",
    "                    data_splits['X_train_flat'], data_splits['y_train_flat'],\n",
    "                    data_splits['X_val_flat'], data_splits['y_val_flat'],\n",
    "                    horizon\n",
    "                )\n",
    "                \n",
    "                # Evaluate\n",
    "                xgb_results = self.evaluate_model(\n",
    "                    xgb_model, data_splits['X_test_flat'], data_splits['y_test_flat'],\n",
    "                    'XGBoost', horizon, is_pytorch=False\n",
    "                )\n",
    "                horizon_results['XGBoost'] = xgb_results\n",
    "                self.models[horizon]['XGBoost'] = xgb_model\n",
    "            \n",
    "            # Store results for this horizon\n",
    "            self.results[horizon] = horizon_results\n",
    "            \n",
    "            # Print results summary\n",
    "            print(f\"\\nResults for {horizon}-minute horizon:\")\n",
    "            print(\"-\" * 70)\n",
    "            print(f\"{'Model':<15} {'MAE':<10} {'RMSE':<10} {'R²':<10} {'Dir_Acc':<12}\")\n",
    "            print(\"-\" * 70)\n",
    "            \n",
    "            for model_name, results in horizon_results.items():\n",
    "                print(f\"{model_name:<15} {results['MAE']:<10.6f} {results['RMSE']:<10.6f} \"\n",
    "                      f\"{results['R2']:<10.4f} {results['Directional_Accuracy']:<12.4f}\")\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "\n",
    "class ImprovedResultsAnalyzer:\n",
    "    \"\"\"Enhanced results analyzer with better visualizations.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ImprovedConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def create_results_summary(self, results: Dict) -> pd.DataFrame:\n",
    "        \"\"\"Create a comprehensive summary DataFrame.\"\"\"\n",
    "        summary_data = []\n",
    "        \n",
    "        for horizon, horizon_results in results.items():\n",
    "            for model_name, metrics in horizon_results.items():\n",
    "                summary_data.append({\n",
    "                    'Horizon (min)': horizon,\n",
    "                    'Model': model_name,\n",
    "                    'MAE': metrics['MAE'],\n",
    "                    'RMSE': metrics['RMSE'],\n",
    "                    'R²': metrics['R2'],\n",
    "                    'Directional_Accuracy': metrics['Directional_Accuracy']\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(summary_data)\n",
    "    \n",
    "    def plot_results_comparison(self, results: Dict, save_path: str = None):\n",
    "        \"\"\"Create comprehensive comparison plots.\"\"\"\n",
    "        summary_df = self.create_results_summary(results)\n",
    "        \n",
    "        if summary_df.empty:\n",
    "            print(\"No results to plot\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle('Model Performance Comparison - Improved System', fontsize=16)\n",
    "        \n",
    "        # MAE comparison\n",
    "        try:\n",
    "            pivot_mae = summary_df.pivot(index='Horizon (min)', columns='Model', values='MAE')\n",
    "            pivot_mae.plot(kind='bar', ax=axes[0, 0])\n",
    "            axes[0, 0].set_title('Mean Absolute Error (MAE) - Lower is Better')\n",
    "            axes[0, 0].set_ylabel('MAE')\n",
    "            axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            axes[0, 0].grid(True, alpha=0.3)\n",
    "        except Exception as e:\n",
    "            axes[0, 0].text(0.5, 0.5, f'Error plotting MAE: {e}', ha='center', va='center')\n",
    "        \n",
    "        # R² comparison\n",
    "        try:\n",
    "            pivot_r2 = summary_df.pivot(index='Horizon (min)', columns='Model', values='R²')\n",
    "            pivot_r2.plot(kind='bar', ax=axes[0, 1])\n",
    "            axes[0, 1].set_title('R-squared (R²) - Higher is Better')\n",
    "            axes[0, 1].set_ylabel('R²')\n",
    "            axes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "        except Exception as e:\n",
    "            axes[0, 1].text(0.5, 0.5, f'Error plotting R²: {e}', ha='center', va='center')\n",
    "        \n",
    "        # Directional Accuracy comparison\n",
    "        try:\n",
    "            pivot_dir = summary_df.pivot(index='Horizon (min)', columns='Model', values='Directional_Accuracy')\n",
    "            pivot_dir.plot(kind='bar', ax=axes[1, 0])\n",
    "            axes[1, 0].set_title('Directional Accuracy - Higher is Better')\n",
    "            axes[1, 0].set_ylabel('Accuracy')\n",
    "            axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "        except Exception as e:\n",
    "            axes[1, 0].text(0.5, 0.5, f'Error plotting Directional Accuracy: {e}', ha='center', va='center')\n",
    "        \n",
    "        # Model ranking by R²\n",
    "        try:\n",
    "            best_models = summary_df.loc[summary_df.groupby('Horizon (min)')['R²'].idxmax()]\n",
    "            colors = plt.cm.Set3(np.linspace(0, 1, len(best_models)))\n",
    "            \n",
    "            bars = axes[1, 1].bar(best_models['Horizon (min)'], best_models['R²'], color=colors)\n",
    "            axes[1, 1].set_title('Best Model R² by Horizon')\n",
    "            axes[1, 1].set_xlabel('Horizon (minutes)')\n",
    "            axes[1, 1].set_ylabel('R²')\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add model names as labels\n",
    "            for i, (bar, model_name) in enumerate(zip(bars, best_models['Model'])):\n",
    "                height = bar.get_height()\n",
    "                axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "                               model_name, ha='center', va='bottom', rotation=45, fontsize=9)\n",
    "        except Exception as e:\n",
    "            axes[1, 1].text(0.5, 0.5, f'Error plotting best models: {e}', ha='center', va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Comparison plot saved to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return summary_df\n",
    "    \n",
    "    def plot_prediction_analysis(self, results: Dict, horizon: int, save_path: str = None):\n",
    "        \"\"\"Plot detailed prediction analysis for a specific horizon.\"\"\"\n",
    "        if horizon not in results:\n",
    "            print(f\"No results available for {horizon}-minute horizon\")\n",
    "            return\n",
    "        \n",
    "        horizon_results = results[horizon]\n",
    "        n_models = len(horizon_results)\n",
    "        \n",
    "        if n_models == 0:\n",
    "            print(\"No models to analyze\")\n",
    "            return\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (model_name, model_results) in enumerate(horizon_results.items()):\n",
    "            if i >= 4:  # Only plot first 4 models\n",
    "                break\n",
    "            \n",
    "            predictions = model_results['predictions'][:200]  # Plot first 200 predictions\n",
    "            actual = np.arange(len(predictions))  # This should be actual values, but we'll use indices\n",
    "            \n",
    "            # Scatter plot of predictions\n",
    "            axes[i].scatter(range(len(predictions)), predictions, alpha=0.6, s=20)\n",
    "            axes[i].plot(range(len(predictions)), predictions, alpha=0.5, linewidth=1)\n",
    "            axes[i].set_title(f'{model_name} - {horizon}min\\nR² = {model_results[\"R2\"]:.4f}')\n",
    "            axes[i].set_xlabel('Time Step')\n",
    "            axes[i].set_ylabel('Predicted Return')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            axes[i].axhline(y=0, color='red', linestyle='--', alpha=0.7, linewidth=1)\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for i in range(n_models, 4):\n",
    "            axes[i].set_visible(False)\n",
    "        \n",
    "        plt.suptitle(f'Prediction Analysis for {horizon}-minute Horizon (First 200 predictions)', \n",
    "                     fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Prediction analysis saved to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def plot_feature_importance(self, model, feature_names, model_name: str, save_path: str = None):\n",
    "        \"\"\"Plot feature importance for tree-based models.\"\"\"\n",
    "        try:\n",
    "            if hasattr(model, 'feature_importances_'):  # XGBoost, RandomForest\n",
    "                importances = model.feature_importances_\n",
    "            elif hasattr(model, 'get_score'):  # XGBoost alternative\n",
    "                importance_dict = model.get_score(importance_type='weight')\n",
    "                importances = [importance_dict.get(f'f{i}', 0) for i in range(len(feature_names))]\n",
    "            else:\n",
    "                print(f\"Feature importance not available for {model_name}\")\n",
    "                return\n",
    "            \n",
    "            # Create DataFrame and sort\n",
    "            feature_imp_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': importances\n",
    "            }).sort_values('importance', ascending=True)\n",
    "            \n",
    "            # Plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(range(len(feature_imp_df)), feature_imp_df['importance'])\n",
    "            plt.yticks(range(len(feature_imp_df)), feature_imp_df['feature'])\n",
    "            plt.xlabel('Feature Importance')\n",
    "            plt.title(f'Feature Importance - {model_name}')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if save_path:\n",
    "                plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "                print(f\"Feature importance plot saved to {save_path}\")\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting feature importance: {e}\")\n",
    "    \n",
    "    def save_results(self, results: Dict, models: Dict, data_loader: ImprovedDataLoader, save_dir: str):\n",
    "        \"\"\"Save comprehensive results and models.\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # Save results summary\n",
    "            summary_df = self.create_results_summary(results)\n",
    "            summary_df.to_csv(os.path.join(save_dir, 'results_summary.csv'), index=False)\n",
    "            \n",
    "            # Save detailed results\n",
    "            with open(os.path.join(save_dir, 'detailed_results.json'), 'w') as f:\n",
    "                json_results = {}\n",
    "                for horizon, horizon_results in results.items():\n",
    "                    json_results[str(horizon)] = {}\n",
    "                    for model_name, metrics in horizon_results.items():\n",
    "                        json_results[str(horizon)][model_name] = {\n",
    "                            'MAE': float(metrics['MAE']),\n",
    "                            'RMSE': float(metrics['RMSE']),\n",
    "                            'R2': float(metrics['R2']),\n",
    "                            'Directional_Accuracy': float(metrics['Directional_Accuracy']),\n",
    "                            'predictions_sample': metrics['predictions'][:50].tolist()  # Save sample\n",
    "                        }\n",
    "                json.dump(json_results, f, indent=2)\n",
    "            \n",
    "            # Save models\n",
    "            for horizon, horizon_models in models.items():\n",
    "                for model_name, model in horizon_models.items():\n",
    "                    try:\n",
    "                        if hasattr(model, 'state_dict'):  # PyTorch model\n",
    "                            torch.save(model.state_dict(), \n",
    "                                     os.path.join(save_dir, f'{model_name}_{horizon}min.pth'))\n",
    "                        elif hasattr(model, 'save_model'):  # XGBoost model\n",
    "                            model.save_model(os.path.join(save_dir, f'{model_name}_{horizon}min.json'))\n",
    "                        else:  # Other models (like baseline)\n",
    "                            with open(os.path.join(save_dir, f'{model_name}_{horizon}min.pkl'), 'wb') as f:\n",
    "                                pickle.dump(model, f)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error saving model {model_name}: {e}\")\n",
    "            \n",
    "            # Save scalers and preprocessors\n",
    "            with open(os.path.join(save_dir, 'scaler.pkl'), 'wb') as f:\n",
    "                pickle.dump(data_loader.scaler, f)\n",
    "            \n",
    "            if data_loader.feature_selector:\n",
    "                with open(os.path.join(save_dir, 'feature_selector.pkl'), 'wb') as f:\n",
    "                    pickle.dump(data_loader.feature_selector, f)\n",
    "            \n",
    "            print(f\"Results and models saved to {save_dir}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results: {e}\")\n",
    "\n",
    "\n",
    "class ImprovedCryptoPredictionSystem:\n",
    "    \"\"\"Main improved prediction system.\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file: str = None):\n",
    "        self.config = ImprovedConfig()\n",
    "        if csv_file:\n",
    "            self.config.csv_file = csv_file\n",
    "        \n",
    "        self.data_loader = ImprovedDataLoader(self.config)\n",
    "        self.trainer = ImprovedModelTrainer(self.config)\n",
    "        self.analyzer = ImprovedResultsAnalyzer(self.config)\n",
    "    \n",
    "    def run_experiment(self, experiment_name: str = \"improved_crypto_experiment\"):\n",
    "        \"\"\"Run the complete improved prediction experiment.\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"IMPROVED CRYPTOCURRENCY PRICE PREDICTION SYSTEM\")\n",
    "        print(\"Predicting percentage returns with proper methodology\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Load and prepare data\n",
    "            print(\"\\n1. Loading and preparing data...\")\n",
    "            self.data_loader.load_data(self.config.csv_file)\n",
    "            self.data_loader.engineer_features()\n",
    "            self.data_loader.create_targets()\n",
    "            \n",
    "            print(f\"Final feature shape: {self.data_loader.features.shape}\")\n",
    "            print(f\"Features with good variance: {(self.data_loader.features.var() > 1e-6).sum()}\")\n",
    "            \n",
    "            # Step 2: Train all models\n",
    "            print(\"\\n2. Training models...\")\n",
    "            results = self.trainer.train_all_models(self.data_loader)\n",
    "            \n",
    "            if not results:\n",
    "                print(\"No models were trained successfully.\")\n",
    "                return None, None\n",
    "            \n",
    "            # Step 3: Analyze results\n",
    "            print(\"\\n3. Analyzing results...\")\n",
    "            \n",
    "            # Create output directory with timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_dir = f\"{self.config.output_dir}_{experiment_name}_{timestamp}\"\n",
    "            \n",
    "            # Generate summary\n",
    "            summary_df = self.analyzer.create_results_summary(results)\n",
    "            print(\"\\nFinal Results Summary:\")\n",
    "            print(\"=\" * 100)\n",
    "            print(summary_df.to_string(index=False, float_format='%.6f'))\n",
    "            \n",
    "            # Step 4: Create visualizations\n",
    "            print(\"\\n4. Creating visualizations...\")\n",
    "            \n",
    "            # Overall comparison\n",
    "            self.analyzer.plot_results_comparison(\n",
    "                results, \n",
    "                save_path=os.path.join(output_dir, 'model_comparison.png') if output_dir else None\n",
    "            )\n",
    "            \n",
    "            # Prediction analysis for each horizon\n",
    "            for horizon in self.config.prediction_horizons:\n",
    "                if horizon in results:\n",
    "                    self.analyzer.plot_prediction_analysis(\n",
    "                        results, horizon,\n",
    "                        save_path=os.path.join(output_dir, f'predictions_{horizon}min.png') if output_dir else None\n",
    "                    )\n",
    "            \n",
    "            # Feature importance plots\n",
    "            for horizon in results:\n",
    "                if 'XGBoost' in self.trainer.models.get(horizon, {}):\n",
    "                    xgb_model = self.trainer.models[horizon]['XGBoost']\n",
    "                    if hasattr(self.data_loader, 'selected_feature_names'):\n",
    "                        self.analyzer.plot_feature_importance(\n",
    "                            xgb_model, self.data_loader.selected_feature_names,\n",
    "                            f'XGBoost_{horizon}min',\n",
    "                            save_path=os.path.join(output_dir, f'feature_importance_xgb_{horizon}min.png') if output_dir else None\n",
    "                        )\n",
    "            \n",
    "            # Step 5: Save results\n",
    "            print(\"\\n5. Saving results...\")\n",
    "            if output_dir:\n",
    "                self.analyzer.save_results(results, self.trainer.models, self.data_loader, output_dir)\n",
    "            \n",
    "            # Print insights\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"EXPERIMENT INSIGHTS:\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            if not summary_df.empty:\n",
    "                # Best models by R²\n",
    "                print(\"\\nBest Models by Horizon (based on R²):\")\n",
    "                print(\"-\" * 50)\n",
    "                best_models = summary_df.loc[summary_df.groupby('Horizon (min)')['R²'].idxmax()]\n",
    "                for _, row in best_models.iterrows():\n",
    "                    print(f\"{row['Horizon (min)']}min: {row['Model']} \"\n",
    "                          f\"(R² = {row['R²']:.4f}, Dir_Acc = {row['Directional_Accuracy']:.4f})\")\n",
    "                \n",
    "                # Performance interpretation\n",
    "                print(f\"\\nPerformance Interpretation:\")\n",
    "                print(\"-\" * 30)\n",
    "                max_r2 = summary_df['R²'].max()\n",
    "                if max_r2 > 0.01:\n",
    "                    print(\"✓ Good: Some models show predictive power (R² > 0.01)\")\n",
    "                elif max_r2 > 0.005:\n",
    "                    print(\"○ Fair: Modest predictive power (R² > 0.005)\")\n",
    "                else:\n",
    "                    print(\"✗ Poor: Very low predictive power - crypto is very noisy\")\n",
    "                \n",
    "                max_dir_acc = summary_df['Directional_Accuracy'].max()\n",
    "                if max_dir_acc > 0.52:\n",
    "                    print(\"✓ Good: Models can predict direction better than random\")\n",
    "                elif max_dir_acc > 0.51:\n",
    "                    print(\"○ Fair: Slight directional prediction ability\")\n",
    "                else:\n",
    "                    print(\"✗ Poor: No meaningful directional prediction\")\n",
    "            \n",
    "            print(f\"\\nExperiment completed! Results saved to: {output_dir}\")\n",
    "            \n",
    "            return results, output_dir\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during experiment: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None, None\n",
    "    \n",
    "    def predict_future(self, horizon: int, model_name: str = None) -> Dict:\n",
    "        \"\"\"Make predictions for future time steps.\"\"\"\n",
    "        if horizon not in self.trainer.models:\n",
    "            available_horizons = list(self.trainer.models.keys())\n",
    "            raise ValueError(f\"No models trained for {horizon}-minute horizon. Available: {available_horizons}\")\n",
    "        \n",
    "        available_models = list(self.trainer.models[horizon].keys())\n",
    "        \n",
    "        if model_name is None:\n",
    "            # Use the best available model (prefer non-baseline)\n",
    "            non_baseline_models = [m for m in available_models if m != 'Baseline']\n",
    "            model_name = non_baseline_models[0] if non_baseline_models else available_models[0]\n",
    "        elif model_name not in available_models:\n",
    "            raise ValueError(f\"Model {model_name} not available. Available: {available_models}\")\n",
    "        \n",
    "        model = self.trainer.models[horizon][model_name]\n",
    "        \n",
    "        # Get latest data for prediction\n",
    "        latest_features = self.data_loader.features.iloc[-self.config.sequence_length:].values\n",
    "        \n",
    "        # Apply same preprocessing as training\n",
    "        if self.data_loader.feature_selector:\n",
    "            latest_features_selected = self.data_loader.feature_selector.transform(latest_features)\n",
    "        else:\n",
    "            latest_features_selected = latest_features\n",
    "        \n",
    "        latest_features_scaled = self.data_loader.scaler.transform(latest_features_selected)\n",
    "        \n",
    "        if model_name == 'Baseline':\n",
    "            # Baseline model predicts no change\n",
    "            prediction = 0.0\n",
    "        elif hasattr(model, 'eval'):  # PyTorch model\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                X_tensor = torch.FloatTensor(latest_features_scaled).unsqueeze(0).to(self.config.device)\n",
    "                prediction = model(X_tensor).cpu().numpy().flatten()[0]\n",
    "        else:  # XGBoost or other\n",
    "            # For non-sequential models, use the last row only\n",
    "            latest_row = latest_features_scaled[-1:] if len(latest_features_scaled.shape) > 1 else latest_features_scaled.reshape(1, -1)\n",
    "            if hasattr(model, 'predict'):\n",
    "                if 'xgb' in str(type(model)).lower():\n",
    "                    dtest = xgb.DMatrix(latest_row)\n",
    "                    prediction = model.predict(dtest)[0]\n",
    "                else:\n",
    "                    prediction = model.predict(latest_row)[0]\n",
    "            else:\n",
    "                prediction = model.predict(latest_row)[0]\n",
    "        \n",
    "        # Get current price for conversion\n",
    "        current_price = self.data_loader.data[self.config.target_col].iloc[-1]\n",
    "        predicted_price = current_price * (1 + prediction)\n",
    "        \n",
    "        return {\n",
    "            'horizon_minutes': horizon,\n",
    "            'model_used': model_name,\n",
    "            'predicted_return': float(prediction),\n",
    "            'current_price': float(current_price),\n",
    "            'predicted_price': float(predicted_price),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the improved cryptocurrency prediction system.\"\"\"\n",
    "    \n",
    "    print(\"Initializing IMPROVED Cryptocurrency Prediction System...\")\n",
    "    print(\"Key improvements:\")\n",
    "    print(\"- Predicting percentage returns instead of raw prices\")\n",
    "    print(\"- Proper feature engineering without data leakage\")\n",
    "    print(\"- Simpler models to prevent overfitting\")\n",
    "    print(\"- Better evaluation metrics\")\n",
    "    print(\"- Baseline comparison\")\n",
    "    \n",
    "    # Option 1: Use with your CSV file\n",
    "    csv_file = \"./3_months_of_days_of_crypto_(1m).csv\"  # Update this path\n",
    "    \n",
    "    if os.path.exists(csv_file):\n",
    "        system = ImprovedCryptoPredictionSystem(csv_file)\n",
    "        print(f\"Using CSV file: {csv_file}\")\n",
    "    else:\n",
    "        # Option 2: Use live data\n",
    "        system = ImprovedCryptoPredictionSystem()\n",
    "        print(\"CSV file not found. Will use live data from Coinbase.\")\n",
    "    \n",
    "    # Configure which models to train\n",
    "    system.config.models_to_train = {\n",
    "        'SimpleLSTM': True,\n",
    "        'BaselineModel': True,  # Always include baseline\n",
    "        'XGBoost': True,  # Enable XGBoost\n",
    "    }\n",
    "    \n",
    "    # Run the experiment\n",
    "    results, output_dir = system.run_experiment(\"improved_bitcoin_prediction\")\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"EXPERIMENT COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Example of making future predictions\n",
    "        print(\"\\nMaking sample predictions...\")\n",
    "        try:\n",
    "            for horizon in system.config.prediction_horizons:\n",
    "                if horizon in results:\n",
    "                    prediction = system.predict_future(horizon)\n",
    "                    print(f\"\\nPrediction for {horizon} minutes ahead:\")\n",
    "                    print(f\"  Current price: ${prediction['current_price']:.2f}\")\n",
    "                    print(f\"  Predicted return: {prediction['predicted_return']:.4f} ({prediction['predicted_return']*100:.2f}%)\")\n",
    "                    print(f\"  Predicted price: ${prediction['predicted_price']:.2f}\")\n",
    "                    print(f\"  Model used: {prediction['model_used']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "        \n",
    "        # Provide usage instructions\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(\"HOW TO USE THE RESULTS:\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"1. All results are saved in: {output_dir}\")\n",
    "        print(\"2. Check 'results_summary.csv' for model performance comparison\")\n",
    "        print(\"3. Look at the generated plots to understand model behavior\")\n",
    "        print(\"4. R² > 0.01 is actually good for 1-minute crypto prediction\")\n",
    "        print(\"5. Directional accuracy > 52% means the model beats random guessing\")\n",
    "        print(\"6. Compare all models to the Baseline to ensure they add value\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Experiment failed. Check error messages above.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CRYPTOCURRENCY PRICE PREDICTION SYSTEM\n",
      "============================================================\n",
      "\n",
      "1. Loading and preparing data...\n",
      "Loading data from ./3_months_of_days_of_crypto_(1m).csv\n",
      "Loaded data shape: (133917, 6)\n",
      "Date range: 2024-09-07 00:38:00 to 2024-12-09 23:59:00\n",
      "Engineering features...\n",
      "Feature engineering complete. Shape: (115593, 30)\n",
      "Creating target variables...\n",
      "Target variables created for horizons: [5, 10, 15]\n",
      "Final feature shape: (115578, 28)\n",
      "Available features: ['Open', 'High', 'Low', 'Volume', 'Price_Change', 'Price_Range', 'Price_Position', 'SMA_5', 'Price_to_SMA_5', 'SMA_10', 'Price_to_SMA_10', 'SMA_20', 'Price_to_SMA_20', 'EMA_12', 'EMA_26', 'MACD', 'BB_Middle', 'BB_Std', 'BB_Upper', 'BB_Lower', 'BB_Position', 'RSI', 'Volume_SMA', 'Volume_Ratio', 'Volatility', 'Hour', 'DayOfWeek', 'IsWeekend']\n",
      "\n",
      "2. Training models...\n",
      "Starting model training...\n",
      "\n",
      "==================================================\n",
      "Training models for 5-minute horizon\n",
      "==================================================\n",
      "Splitting data for 5-minute horizon...\n",
      "Training LSTM for 5-minute horizon...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m system\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;66;03m#30 # Reduce for faster testing\u001b[39;00m\n\u001b[0;32m     14\u001b[0m system\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_horizons \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m]  \u001b[38;5;66;03m# Test with fewer horizons\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m results, output_dir \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcustom_experiment_for_365_days_of_1_minute_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExperiment completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 881\u001b[0m, in \u001b[0;36mCryptoPredictionSystem.run_experiment\u001b[1;34m(self, experiment_name)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# Step 2: Train all models\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2. Training models...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 881\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_all_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;66;03m# Step 3: Analyze results\u001b[39;00m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m3. Analyzing results...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 568\u001b[0m, in \u001b[0;36mModelTrainer.train_all_models\u001b[1;34m(self, data_loader)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodels_to_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    563\u001b[0m     lstm_model \u001b[38;5;241m=\u001b[39m LSTMModel(\n\u001b[0;32m    564\u001b[0m         input_size\u001b[38;5;241m=\u001b[39minput_size,\n\u001b[0;32m    565\u001b[0m         hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlstm_hidden_size,\n\u001b[0;32m    566\u001b[0m         num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlstm_num_layers\n\u001b[0;32m    567\u001b[0m     )\n\u001b[1;32m--> 568\u001b[0m     lstm_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_pytorch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLSTM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     lstm_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_model(\n\u001b[0;32m    572\u001b[0m         lstm_model, data_splits[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test\u001b[39m\u001b[38;5;124m'\u001b[39m], data_splits[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m, horizon\n\u001b[0;32m    573\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[13], line 400\u001b[0m, in \u001b[0;36mModelTrainer.train_pytorch_model\u001b[1;34m(self, model, train_loader, val_loader, horizon, model_name)\u001b[0m\n\u001b[0;32m    398\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    399\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m--> 400\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    401\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m    403\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mikey\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:101\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor betas[1] must be 1-element\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m     89\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m     90\u001b[0m     betas\u001b[38;5;241m=\u001b[39mbetas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m     decoupled_weight_decay\u001b[38;5;241m=\u001b[39mdecoupled_weight_decay,\n\u001b[0;32m    100\u001b[0m )\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32mc:\\Users\\mikey\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:400\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    397\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mikey\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_compile.py:46\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m disable_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dynamo_disable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# We can safely turn off functools.wraps here because the inner\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# already wraps fn in the outer scope.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive, wrapping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\mikey\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\__init__.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, eval_frame, resume_execution\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[1;32mc:\\Users\\mikey\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallbackTrigger\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:969\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1091\u001b[0m, in \u001b[0;36mpath_stats\u001b[1;34m(self, path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "# THIS IS THE OLD EXECUTION\n",
    "system = CryptoPredictionSystem(\"./3_months_of_days_of_crypto_(1m).csv\")\n",
    "\n",
    "system.config.models_to_train = {\n",
    "        'LSTM': True,\n",
    "        'CNN_LSTM': True,\n",
    "        'Transformer': True,\n",
    "        'LSTM_XGBoost': True,\n",
    "        'RL_Agent': False  # Keep disabled for now\n",
    "    }\n",
    "\n",
    "# Optionally modify other configuration\n",
    "system.config.epochs = 20 #30 # Reduce for faster testing\n",
    "system.config.prediction_horizons = [5, 10, 15]  # Test with fewer horizons\n",
    "\n",
    "results, output_dir = system.run_experiment(\"custom_experiment_for_365_days_of_1_minute_data\")\n",
    "\n",
    "if results:\n",
    "    print(\"\\nExperiment completed successfully!\")\n",
    "\n",
    "    # Example of making future predictions\n",
    "    print(\"\\nMaking sample predictions...\")\n",
    "    try:\n",
    "        for horizon in [5, 10]:\n",
    "            prediction = system.predict_future(horizon)\n",
    "            print(f\"Prediction for {horizon} minutes ahead: ${prediction['predicted_price']:.2f}\")\n",
    "            print(f\"Model used: {prediction['model_used']}\")\n",
    "            print(\"-\" * 30)\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Experiment failed. Check error messages above.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8221376,
     "sourceId": 12988758,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a388e0ebdc84ec3be09ce41633d5c07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2101f259b5b845898861b8d8cb372a1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Username:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_316ed3ef48fb4fb0b4d2cb9bd69f32bb",
      "placeholder": "​",
      "style": "IPY_MODEL_b2c3361ded084e6587dad9f69e67eb05",
      "value": "mikewschmidt"
     }
    },
    "3140d096799341b18e6173cd9d3130b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b46ba47271d407a833bf2442a0e9fa3",
      "placeholder": "​",
      "style": "IPY_MODEL_8903a21e3d224f658b16f681db367d6e",
      "value": "Kaggle credentials successfully validated."
     }
    },
    "316ed3ef48fb4fb0b4d2cb9bd69f32bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a9b484eac9e4aff97012ab630d82552": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "4058f94f750e4bcfb254850814513eb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_7e6e8fbc01864124b90a3b69a2afbecb",
      "style": "IPY_MODEL_3a9b484eac9e4aff97012ab630d82552",
      "tooltip": ""
     }
    },
    "4741abde921f4498b36838d9189bdb9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "4bc7e65dfb5d4b00a7a358d8882ca074": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4073318641446769d0af98c9deb6508",
      "placeholder": "​",
      "style": "IPY_MODEL_5a2cc1e2896b43f4897d0c87ade36963",
      "value": "\n<b>Thank You</b></center>"
     }
    },
    "575d6f04956f4ba78a079c98540420c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a29762b99564463980cd38797a86bd67",
      "placeholder": "​",
      "style": "IPY_MODEL_cb6da7108884416e96750a01ca70c115",
      "value": "Connecting..."
     }
    },
    "5a2cc1e2896b43f4897d0c87ade36963": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5fe34be08a604d04a38b4ebbf1a12bc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3140d096799341b18e6173cd9d3130b6"
      ],
      "layout": "IPY_MODEL_4741abde921f4498b36838d9189bdb9d"
     }
    },
    "7b46ba47271d407a833bf2442a0e9fa3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e6e8fbc01864124b90a3b69a2afbecb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8903a21e3d224f658b16f681db367d6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1cae1a2258345cc820426600a284c2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a29762b99564463980cd38797a86bd67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a79eb373af6147c3b898fba907ea06e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af330227150b44e4aca950286f9839ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a79eb373af6147c3b898fba907ea06e7",
      "placeholder": "​",
      "style": "IPY_MODEL_a1cae1a2258345cc820426600a284c2c",
      "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
     }
    },
    "b2c3361ded084e6587dad9f69e67eb05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4073318641446769d0af98c9deb6508": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7d6c398add9491d820b2f5d74aa6bfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_d41f0e9fae4d4cb4b0f910f438c0f4a5",
      "placeholder": "​",
      "style": "IPY_MODEL_0a388e0ebdc84ec3be09ce41633d5c07",
      "value": ""
     }
    },
    "cb6da7108884416e96750a01ca70c115": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d41f0e9fae4d4cb4b0f910f438c0f4a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
